\documentclass[../class_mech_main.tex]{subfiles}
%\input{../header} \graphicspath{../}


\begin{document}


% \chapter{Erweiterungen von Newton}
\chapter{Analytical Mechanics}

Newtonian mechanics provided a description of the world in terms of forces and momenta. This is convenient for many applications, but not for all. Sometimes, it is more beneficial to adopt different viewpoints on the physical world, and we present several alternative frameworks in this chapter. These are often summarized under the term \enquote{analytical mechanics}. Two well-known branches of this are the Lagrangian and the Hamiltonian one.


% -> maybe say that we switch to fields (?) and generalized coordinates + momenta


-> Lagrange and Hamiltonian approach things in terms of energy (yes, Lagrange as well; $\mathcal{L} = T - V$ in many cases) -> conceptually different, but also mathematically because this means we mainly work with scalars from now on! Not vectors anymore



	\section{Constraints \& Setup}
In many cases, physical objects are not free to evolve in the presence of forces, but instead subject to certain \Def{constraints}. Easy examples are balls attached to some rigid rod, i.e.~basically a pendulum. This ball is free not to move in all spatial dimensions, but must always maintain a fixed distance from the pendulum's pivot since it is attached to the rod -- this is a constraint. In Newtonian terms, this manifests as a \Def{constraint force} $\vec{C}$ exerted by the rod.



\begin{table}
	% \definecolor{namecellcolor}{named}{gray!30}
	% \colorlet{namecellcolor}{gray!30}
	\colorlet{namecellcolor}{white}
	\centering
	\begin{tabular}{ccc}
		\toprule
		\toprule
		% 
		\cellcolor{namecellcolor} holonomic & & $\eqbox{f = 0}$
		\\
		\midrule
		% \cellcolor{namecellcolor} non-holonomic & \multicolumn{3}{c}{$\eqbox{\sum_{m = 1}^{S} f_{im} dx_m + f_{it} dt}$}
		% \cellcolor{namecellcolor} non-holonomic & $\eqbox{\sum_{m = 1}^{S} f_i dx_m + f_t dt}$ & & 
		% 
		% \cellcolor{namecellcolor} non-holonomic & \multicolumn{3}{c}{inequality or non-integrable ($\eqbox{\sum_{m = 1}^{S} f_{im} dx_m + f_{it} dt} \hat{=} \eqbox{\sum_{m = 1}^S a_m dq_m + b_t dt = 0}$)}
		% 
		\cellcolor{namecellcolor} \multirow{2}{*}{non-holonomic} & inequality & e.g., $\eqbox{f \geq 0}$ or $\eqbox{a \leq f \leq b}$
		\\
		 & non-integrable & $\eqbox{\sum_{i = 1}^{S} f_i dx_i + f_t dt} \ \hat{=} \ \eqbox{\sum_{j = 1}^S a_j dq_j + b_t dt = 0}$ \todo{remove from here? Because this is Pfaffian form, right?}
		%  
		\\
		\midrule
		\cellcolor{namecellcolor} scleronomic & \multicolumn{2}{c}{not time dependent}
		\\
		\midrule
		\cellcolor{namecellcolor} rheonomic & \multicolumn{2}{c}{time dependent}
		\\
		\bottomrule
		\bottomrule
	\end{tabular}
	\label{tab:constraint_types}

	\caption{Different types of constraints.}
\end{table}



Many different types of constraints exist. A rough classification is provided in Tab.~\ref{v}.

second form of non-holonomic is given in differential form, but is not integrable (cannot be rewritten as total differential $dg$)

-> no general solution exists for non-holonomic systems!


holonomic forces only involve the generalized coordinates; non-holonomic ones also involve their velocities or higher derivatives



note that in table, we put no index on constraints; but there can be multiple, then each constraint would need an index


-> we can bring constraints into Pfaffian form: ... (\url{https://en.wikipedia.org/wiki/Pfaffian_constraint})






	\section{Lagrange-Formalism}
If we now envision more complex systems, where many such constraints are present, things quickly becomes hard too handle from the Newtonian point of view. This is why other approaches to mechanics are worthwhile exploring, founded on different principles than simply deriving an equation of motion straight from Newton's second law.


Before showing how this can be done, we will present the general setup assumed henceforth: there are $N$ particles, each described by a position $\vec{x}_i$, i.e.~in total $3 N$ degrees of freedom. One of the first major changes compared to Newtonian physics is the type of coordinates used. Instead of restricting ourselves to the actual, spatial positions $\vec{x}$ of the physical system we wish to describe, it turns out to be beneficial to work with \Def{generalized coordinates} $q$.\footnote{Note that we choose to omit the arrow above $q$ here. The reason is that, as we will see later, $q$ can be interpreted as a point on a manifold. Unlike in Euclidean space, this is now a distinct notion from vectors, which cannot be interpreted in terms of position vectors.} Accordingly, one defines the \Def{generalized velocity} as $v = \dot{q} = \dv{q}{t}$.


% Depending on the number of (holonomic) constraints $p$, $S = 3 N - p$ generalized coordinates are needed to describe the system. One requirement on them is that we can express the particle positions in terms of the generalized coordinates, $\vec{x} = \vec{x}(q_1, \dots, q_S)$ must be possible $\forall i$.
Depending on the number and type of constraints, the number $S$ of generalized coordinates needed to describe the system can be $\leq 3N$. One requirement on them is that we can express the particle positions in terms of the generalized coordinates, $\vec{x} = \vec{x}(q_1, \dots, q_S)$ must be possible $\forall i$.




		\subsection{D'Alembert Principle}
% -- Awesome for basic idea: https://en.wikipedia.org/wiki/Virtual_work#Overview

Say we have a particle moving with forces acting on it, so that one can compute the work done by these forces along the trajectory $\vec{x}(t)$. The \Def{principle of virtual work} states that for the path that the particle actually takes, the work remains unchanged upon small variations of this path (unchanged to first order).\footnote{This can be regarded as an application of the principle of least action, that we will encounter later.} This is a variational principle, that can be formalized in the equation
\begin{equation}\label{eq:principle_virtual_work_basic}
	\eqbox{
		\delta W = \vec{F} \cdot \delta \vec{x} = 0
	} \, .
\end{equation}
$\delta W$ denotes the \Def{virtual work} done upon the \Def{virtual displacement} $\delta \vec{x}$ from the particle's path. These virtual displacements should not be thought of as \enquote{real} displacements in space, as they happen instantaneously.
% \todo{is that reason why we have no integral here over $t$? Hmm no, don't think so, integral over $t$ would appear if we had $\vec{F} \cdot \vec{v}$ here... So actually we are kind of lacking an integral over path here...}

The contribution by d'Alembert was to recognize that not only does the force on the particle get contributions from net external forces, which we denote by $\vec{K}$ here, and from the net force $\vec{C}$ arising from the constraints on the system, but also from the inertial force $- \dv{\vec{p}}{t} \underset{m = \text{const}}{=} - m \vec{a}$ that is required to change the particle's state of motion.
% \footnote{This inertial force is essentially a fictitious force arising from an analysis in the rest frame of the moving body.}
\footnote{Essentially, we take the right hand side of Newton's law $\vec{K} + \vec{Z} = m \vec{a}$ and take the viewpoint that it is a force as well, so that we effectively analyze a system in equilibrium, namely $\vec{F} = 0$. This is also called a dynamical equilibrium because the particle is not necessarily static. In some sense, this means we perform an analysis from the rest frame of the particle (where it is seen to be in equilibrium), where the inertial force arises as a fictitious forces in this frame.}
Newton's second law immediately tells us that, if we include these inertial forces, $\vec{F} = 0$ so that $\delta W = 0$ holds trivially. However, since $\delta W$ contains the inner product of $\vec{C}$ and $\delta \vec{x}$, by selecting a virtual displacement that is consistent with the constraints (e.g., if the constraint is motion along a circle, we choose a displacement tangential to the circle), the principle of virtual work yields
\begin{equation}
	\delta W = \qty(\vec{K} - m \vec{a}) \dot \delta \vec{x} = 0
\end{equation}
where we have assumed $m = \text{const}$ for simplicity. This is an equation where the constraint forces are eliminated entirely -- something that was not possible when working with Newton's second law.\footnote{Notice how this required a paradigm shift. We are now approaching the situation thinking about energy rather than forces. Of course, forces are still involved in the analysis, but only due to their relation to the work done on the system, which is now the origin of the analysis.}

% -> idea is: we have more forces acting than just the inertial forces, namely also force from constraint, which makes Newtons equations really complicated; we can also write down work done by these forces upon some virtual displacement; the key is now that constraint forces do no work -- they drop out of this equation!!!


The generalization to $N$ particles is straightforward, and the principle of virtual work for this situation becomes
\begin{equation}\label{eq:principle_virtual_work_general}
	\eqbox{
		\delta W = - \sum_i \vec{F}_i \cdot \delta \vec{x}_i = 0 = - \sum_j (Q_j + Q^*_j) \delta q_j = - (Q + Q^*) \cdot \delta q
	} \, ,
\end{equation}
still assuming virtual displacements $\delta \vec{x}_i, \delta q$ consistent with the constraints. Note that the sums have different number of terms here, over $j$ goes up to $S$ and over $i$ up to $3N$. At this point, we are starting to write equations in terms of the generalized coordinates $q$, and this requires the definition of an according \Def{generalized force}
\begin{equation}
	\eqbox{
		Q_j = \sum_i \vec{K}_i \cdot \dv{\vec{x}_i}{q_j}
	} \, .
\end{equation}
Similarly, $Q^*$ is the \Def{generalized inertial force}. It is common to rewrite it in terms of the total kinetic energy $T = \sum_i \frac{1}{2} m_i \vec{x}_i \cdot \vec{x}_i$ of the particles as
\begin{equation}
	Q^* = \sum_j \dv{t} \pdv{T}{\dot{q}_j} - \pdv{T}{q_j}
	\, .
\end{equation}
\enquote{Why?}, you may ask. Well, the reason is that this yields equations that resemble the results obtained from Hamilton's principle, which is treated in the next section.

This means Eq.~\eqref{eq:principle_virtual_work_general} can be recast into
\begin{equation}\label{eq:principle_virtual_work_general_v2}
	\eqbox{
		\sum_j \qty[\dv{t} \pdv{T}{\dot{q}_j} - \pdv{T}{q_j} - Q_j] \delta q_j = 0
	} \, ,
\end{equation}
which forms something like a generalized equation of motion.


Unfortunately, we cannot get rid of the sum over $j$ in Eq.~\eqref{eq:principle_virtual_work_general_v2} in general. For this to be possible, the displacements $\delta q_j$ must be linearly independent (while still being consistent with the constraints), which in turn requires independence of the generalized coordinates $q_j$. This, however, is highly dependent on the problem itself, in particular the type of constraints that are present. If the assumption of independent $\delta q_j$ is justified, Eq.~\eqref{eq:principle_virtual_work_general_v2} can be turned into $S$ equations
\begin{equation}\label{eq:principle_virtual_work_general_simplified}
	\eqbox{
		\dv{t} \pdv{T}{\dot{q}_j} - \pdv{T}{q_j} = Q_j
	} \, .
\end{equation}


% In the rest of this section, we will first show that Eq.~\eqref{eq:principle_virtual_work_general_v2} is just Newton's second law in disguise, and then analyze what happens to the most general result Eq.~\eqref{eq:principle_virtual_work_general_v2} if certain additional assumptions about the system can be made.
% \begin{ex}[Relation to Newtonian Mechanics]
% 	no constraints means we can choose simplified Eq.~\eqref{eq:principle_virtual_work_general_simplified}; we assume conservative force for now; choose generalized coordinates as positions...


% 	-> we get second law
% \end{ex}

In the rest of this section, we will analyze what happens to the most general result Eq.~\eqref{eq:principle_virtual_work_general_v2} if certain additional assumptions about the system can be made. For instance, we will discuss when Eq.~\eqref{eq:principle_virtual_work_general_simplified} may be used.



			\paragraph{Holonomic Constraints vs.~Non-holonomic Constraints}


$p$ holonomic constraints means $S = 3N - p$, they truly reduce the number of degrees of freedom in a system; then we can use simplified form -> basically, through suitable choice of generalized coordinates, we automatically make sure constraints are respected (would usually not be possible for positions; that is how constraints drop out in analytical mechanics, but not Newtonian)


non-holonomic constraints will, generally speaking, not reduce the degrees of freedom of the system (easy example: restriction to movement inside of a circle; means particle can still move in all spatial directions, but this is still not completely free movement)


\hrule


ChatGPT on whether constraints impact if independent coordinates can be chosen:

Yes, the choice of generalized coordinates is indeed related to the nature of constraints in the system, specifically distinguishing between holonomic and non-holonomic constraints.

1. Holonomic Constraints:

   - Definition: Holonomic constraints are constraints that can be expressed as equations involving the coordinates and possibly time, but not the velocities. They effectively reduce the degrees of freedom of the system by restricting the configurations that the system can occupy. These are given by constraints of the form \(f(q1, q2, \ldots, q_n, t) = 0\).

   - Relation to Generalized Coordinates: When all constraints in a system are holonomic, it's possible to choose generalized coordinates that are independent and account for these constraints. The generalized coordinates inherently respect the constraints, so any virtual displacement expressed in terms of these coordinates will automatically satisfy the constraints. This makes it possible to express the configuration of the system completely in terms of fewer variables.

2. Non-Holonomic Constraints:

   - Definition: Non-holonomic constraints involve not just the coordinates, but also the velocities, and they cannot be integrated to reduce the coordinates themselves. These are typically expressed in a differential form, like \(g(q1, q2, \ldots, qn, \dot{q}1, \dot{q}2, \ldots, \dot{q}n, t) = 0\). 

   - Relation to Generalized Coordinates: Non-holonomic constraints present a challenge for choosing generalized coordinates since these constraints might impact how velocities or virtual displacements can vary, but not in a way that reduces the coordinate count directly as holonomic constraints do. In these cases, the coordinates may not fully decouple, so the variation of virtual displacements can be restricted by the differential form of the constraint. This means that even though generalized coordinates are designed to capture the system's configuration, the non-holonomic constraints can prevent full independence of $\delta q_j$.

In summary, the choice of generalized coordinates strongly ties in with how constraints are formulated in a system. Holonomic constraints allow for a straightforward reduction in the number of independent coordinates, while non-holonomic constraints typically require more care in describing the system's permissible motions and ensuring that virtual displacements respect the velocity-dependent constraints.



			\paragraph{Holonomic Constraints, Conservative Forces}
simplified form from holonomic is already great, but with conservative forces we can do even more


here we have $\vec{K} = - \nabla V$ for some potential $V = V(\vec{x}) = V(q)$, which implies $Q_j = - \pdv{V}{q_i}$. in that case, we can rearrange stuff and obtain the \Def[Lagrange equations!second kind]{Lagrange equations of second kind}
\begin{equation}\label{eq:ele}
	\eqbox{
		\dv{t} \pdv{\mathcal{L}}{\dot{q}_j} - \pdv{\mathcal{L}}{q_j} = 0
	} \, ,
\end{equation}
also called \Def{Euler-Lagrange equations} (ELEs).


-> $V$ does not explicitly depend on $\dot{q}_i$, while $T$ does not explicitly depend on $q_i$


now we will show that Eq.~\eqref{eq:principle_virtual_work_general_v2} is just Newton's second law in disguise, 
\begin{ex}[Relation to Newtonian Mechanics]
	no constraints means we can choose simplified Eq.~\eqref{eq:principle_virtual_work_general_simplified}; we assume conservative force for now; choose generalized coordinates as positions...


	-> we get second law
\end{ex}



			\paragraph{Holonomic Constraints, Non-Conservative Forces}
Eq.~\eqref{eq:principle_virtual_work_general_simplified} is already nice, but through some tricks we can maintain/preserve form of ELE for even non-conservative forces; for that, define generalized potential $U$ and redefine $\mathcal{L} = T - U$


no potential $V$, but we can define something that plays analogous for the purpose of Lagrangian, i.e.~a generalized potential $U$ with
\begin{equation}
	\eqbox{
		Q_j = \dv{t} \pdv{U}{\dot{q}_j} - \pdv{U}{q_j}
	}
\end{equation}

then from results from d'Alembert principle we see that one can still use ELE, just with modified Lagrangian $\mathcal{L} = T - U$



-> note how this allows us to formulate equations of motion entirely in terms of the Lagrangian, and thus essentially energy; forces only appear indirectly, in definition of potential, but are not the quantity of interest anymore (unlike in Newtonian case)



			\paragraph{Non-Holonomic Constraints}
Note that we will not distinguish between the cases of conservative, non-conservative forces because the Lagrangian $\mathcal{L}$ is defined for both cases, so we can just stick to this function $\mathcal{L}$.


It was already mentioned how one issue with non-holonomic constraints was that they do not remove a degree of freedom from the system, which makes a general treatment impossible. To proceed, we must assume it is still possible to choose independent virtual displacements $\delta q_j$ (which is related to independent generalized coordinates $q_j$). If, in addition to that, the $p'$ non-holonomic constraints that are present further have a Pfaffian form
\begin{equation*}
	\sum_{j = 1}^S a_j dq_j + b_t dt = 0
	\, ,
\end{equation*}
then the following trick can be applied: replace infinitesimal displacements into virtual displacements, i.e.~$d \mapsto \delta$, recall that $\delta t = 0$, and then recognize that the Pfaffian form implies the conditions
\begin{equation}\label{eq:non_hol_pfaffian_deltas}
	\eqbox{
		\sum_{j = 1}^S a_{mj} \delta q_j = 0
	}
\end{equation}
for each constraint with index $m = 1, \dots, p'$. By assigning a Lagrange multiplier $\lambda_m$ to each of the non-holonomic constraints, and noting that Eq.~\eqref{eq:non_hol_prassian_deltas} implies
\begin{equation}\label{eq:non_hol_pfaffian_deltas_as_work}
	\sum_{m = 1}^{p'} \lambda_m \sum_{j = 1}^S a_{mj} \delta q_j = 0
	\, ,
\end{equation}
we can treat constraints in a well-defined mathematical manner. On a phenomenological level, we can see how how the math works by noticing that this situation is reminiscent of the presence of a constraint force $\sum_{m = 1}^{p'} \lambda_m a_{mj}$ that acts on each of the generalized coordinates, with Eq.~\eqref{eq:non_hol_pfaffian_deltas_as_work} meaning they do no work. Including these terms turns the Lagrange equations of second kind into the \Def[Lagrange equations!first kind]{Lagrange equations of first kind}
\begin{equation}
	\eqbox{
		\dv{t} \pdv{\mathcal{L}}{\dot{q}_j} - \pdv{\mathcal{L}}{q_j} = \sum_{m = 1}^{p'} \lambda_m a_{mj}
	} \, .
\end{equation}
Thus, even in case of non-holonomic constraints, it is possible to obtain results that look very much like the ELEs, with small modifications on top.


Now, you may ask why there is a need to include the terms $\sum_{m = 1}^{p'} \lambda_m a_{mj}$ even if they do no work. And you would be right in doing so, after all we were able to neglect these equations before. 

-> reason we need them: more degrees of freedom than ELEs! -> huh, but does that explain why we need to care about them in the ELEs?



I am not entirely sure how relevant this case is, but if we are not able to find independent $\delta q_j$, then we have to work with
\begin{equation}
	\eqbox{
		\sum_j \qty[\dv{t} \pdv{\mathcal{L}}{\dot{q}_j} - \pdv{\mathcal{L}}{q_j} - \sum_{m = 1}^{p'} \lambda_m a_{mj}] \delta q_j = 0
	} \, .
\end{equation}


Note that the method of Lagrange multipliers can also be applied to holonomic constraints.



\hrule


\url{https://en.wikipedia.org/wiki/D%27Alembert%27s_principle#Formulation_using_the_Lagrangian} -> I guess this helps, right?

-> idea is to use method of Lagrange multipliers, which allow extremization subject to certain constraints (i.e.~exactly what we want; and for a reason, Lagrange developed this method for this application)


\begin{ex}[Friction]
	Rayleigh dissipation function

	-> is example of non-holonomic constraint
\end{ex}



		\subsection{Hamilton's Principle}
based on minimizing action -> at least making stationary (thus also name principle of stationary action); abstract idea, but was found to yield correct results for Newton (and many more!)

second variational approach; seems to be more general than virtual work



second way to derive \Def{Euler-Lagrange equations}, under the assumptions of exclusively holonomic constraints (if some are present at all) and conservative forces


-> however, we have already seen how more general situations can be recast into something compatible with ELE; i.e.~we will not reiterate derivation with other constraints again, rather show how varying in the way we done is fine, upon certain adjustments on the result


-> as a note: we could perhaps derive results that take role of ELE in presence of non-holonomic, too (because we were able to obtain them from principle of virtual work, which is special case of least action); but we do not do here




		\subsection{Gauge Transformations}
form basis for Noether

\todo{merge with next subsection?}



		\subsection{Symmetries}
conserved quantities play important role in physics, we had already seen this

-> important role in Lagrangian mechanics as well, we can simplify problems a lot via clever choice of coordinates; -> introduce cyclic as ones on which Lagrangian is not explicitly dependent

Noether



	\section{Hamilton-Formalism}
% basically description in terms of energy instead of momentum, right? since Hamiltonian = energy (?)


		% \subsection{The Mathematical Viewpoint: Transition from Lagrange to Hamilton}
		% \subsection{The Mathematical Perspective: Moving on from Lagrange}
		\subsection{Gaining Momentum(a): Moving on from Lagrange}
% \todo{make section? As nice transition between Lagrange and Hamilton, that still provides something new in the mathematical formulation} -> not if we cut short before Legendre, then subsection is perfect

Here we introduce a very formal way of looking at the Lagrange formalism. What we have done is describe physical system in terms of time $t$, some generalized positions/coordinates $q$, and their derivatives $\dot{q} = \dv{q}{t}$.\footnote{Although $q$ has components, we do not use $\vec{q}$, since it refers to a point on a manifold now. On this abstract object, points are now distinct notions from vectors, unlike in Euclidean space.}
% As it turns out, the generalized coordinate $q_i$ live on a manifold, called \Def{configuration space}.%
As it turns out, the generalized coordinate $q_i$ are indeed coordinates, namely of a manifold called \Def{configuration space}.%
\footnote{In fact, they span this space (note that this does not mean they form a basis of it; it is just that the space consists of all possible $q$). \todo{but doesn't span mean they represent a basis? -> I guess we can just argue via linear independence; same for $v_i, q_i$ as basis tangent, cotangent space}}
The \Def{configuration} of a system at each time $t$ is an element of this space, \todo{so $q(t)$ is a curve in this space}. We could also include $t$ in the space, which yields the \Def{event space}. Both of these spaces can be used to visualize the Lagrange formalism; in the latter, the evolution traces out a curve that is more like a graph, while in the former, time is an \enquote{external} parameter and we have curves only as a function of the $q_i$.


Similarly, the tangent space is spanned by the basis tangent vectors $\pdv{q_i}$ and $\dot{q} = \dv{q}{t}$ lives on it.\todo{isn't that just components of $\dv{t}$ for these Gaussian basis vectors? Since chain rule yields $\dv{t} = \sum_i \dv{q_i}{t} \dv{q_i} = \sum_i \dv{q_i}{t} \pdv{q_i}$ -> yeah, I guess we just define it in coordinates (i.e.~in a chart) here} The pair $(q, \dot{q})$ then lives on something that is referred to as tangent bundle (which is what we get by gluing together the tangent spaces at different points of the manifolds; this is like fibers forming a bundle and justifies the given name), and the Lagrangian is function on that (that has additional parameter in the time $t$).\\


Lagrangian is the perfect keyword here. The way that Lagrangian mechanics works is by solving the ELE \todo{make sure this acronym is introduced}. One practical issue with this approach is that the ELE are second order differential equations, and the total time derivative in particular can lead to very nasty and complicated expressions. Therefore, while we love the capabilities of the Lagrange formalism, it is worthwhile exploring potential alternative formulations of the problem.

After what we said about the underlying mathematical structure, namely that $(q, \dot{q})$ being part of tangent bundle, people familiar with manifolds and differential geometry will (hopefully) agree that it is straightforward to look at the cotangent bundle next. This is obtained by gluing together cotangent spaces, whose elements are maps on the tangent spaces (similarly, tangent vectors as elements of tangent spaces can be considered maps on the cotangent space, there is a duality here), and the term usually used for it in physics is \Def{phase space}. The dual or conjugate variable to $p$ that we are interested in is the \Def{generalized momentum} $\vec{p}$, defined by its components $p_i = \pdv{\mathcal{L}}{q_i}$. \todo{is this natural choice? Or more like "we choose mapping on tangent bundle because it yields good results after Legendre transform"? Which would be fine, this is what we do anyway -> hm actually comes out of Legendre naturally; so maybe not introduce here?}


You may ask why exactly we should do this? Well, the inclusion of a derivative directly into the definition of the $p_i$ should make us hopeful that this may reduce the number of differentiations to carry out. At least, it looks promising enough to follow through.\footnote{This justification is very hand-wavy. To me, this looks like a classical case of: two approaches exist (Lagrangian, Hamiltonian), and people found this cool mathematical relation between them. So this serves as our transition between them. I might be wrong, and a better justification other than \enquote{something good comes out of switching to the conjugate variables} might exist.} This is done in the next section.


-> incorporate following? note that tangent space and cotangent space are manifolds themselves; in particular, one can do things like integrals on them, something that we will see later on with Liouville measure etc; they even got a name, phase space (or state space \todo{this is the german name, certainly not english}, if time is included as well)



		\subsection{Hamiltonian and Hamilton's Equation}

Mapping $(q, \dot{q}) \mapsto (q, p)$ is conceptually very simple as it merely requires calculating the generalized momenta $p_i = \pdv{\mathcal{L}}{q_i}$. But this is not really helpful in itself -- how can we do the same physics as before, i.e.~how can we get what $\mathcal{L}$ is for $\dot{q}_i$ in terms of the $p_i$? Here it finally pays off that we had done before in linking all the physical quantities to fancy mathematical entities; as it turns out, the problem of mapping quantities from the tangent bundle to the cotangent bundle is a problem that is encountered frequently (enough) that a general solution for it exists: the \Def{Legendre transform}\footnote{Fun fact: this transform is also a prominent part of thermodynamics.}; for a function $f(x)$ of two scalar variables $x, y$, the Legendre transform with respect to $x$, is defined as
\begin{equation}
	\eqbox{
		% \Leg\qty[f](u) = \eval{\sup_x \qty{u x - f(x)}}_{x = x(u)}
		\Leg\qty[f](u) = \sup_x \qty{u x - f(x)}
	}
\end{equation}
(formally, it is only applicable in this form if $f$ is convex; we do not care about this because Lagrangians are convex in $\dot{q_i}$). If $f$ is differentiable, this turns into
\begin{equation}
	\eqbox{
		\Leg\qty[f](u) = u x(u) - f(x(u)), \; u = \dv{f}{x}, x(u) = \qty(\dv{f}{x})^{-1}(u)
	} \, .
\end{equation}
For $f$ that have more than one variable, we just keep the other variables fixed (and total derivative must be replaced by partial derivative).


Legendre-transforming the Lagrangian $\mathcal{L}(q, v)$ with respect to $v$ then yields the \Def{Hamiltonian}
\begin{equation}\label{eq:hamiltonian_general}
	\eqbox{
		H(q, p) = \Leg\qty[\mathcal{L}(q, v)](p) = \sup_v \qty{p \cdot v - \mathcal{L}(q, v)}
	}
\end{equation}
where we begin using the abbreviation $v = \dot{q}$ for \Def{generalized velocity}. \todo{I am sure this is introduced beforehand when summary is in more finalized state, adjust this}
Note that this definition holds even for non-differentiable Lagrangians, where we cannot define $p_i$ in the way that we did, but rather take them to be some arbitrary variable. But if $\mathcal{L}$ is differentiable, we can indeed recover the previous definition. This can be done by determining the supremum (maximum) via differentiation:
% 
% Please note that, if we had not defined the $p_i$ as $\pdv{\mathcal{L}}{q_i}$, we would get the same result now. For this, suppose $\mathcal{L}$ is differentiable. Then we can find the supremum (maximum) via differentiation:
\begin{equation}
	0 = \pdv{v_i} \qty(p \cdot v - \mathcal{L}) = p_i - \pdv{\mathcal{L}}{v_i}
	\quad \Leftrightarrow \quad
	p_i = \pdv{\mathcal{L}}{v_i}
	\, .
\end{equation}
Inserting this into Eq.\eqref{eq:hamiltonian_general}, the Hamiltonian becomes
\begin{equation}\label{eq:hamiltonian_differentiable}
	\eqbox{
		% H(q, p) = \Leg\qty{\mathcal{L}(q, v)}(p) = \sum_i p_i v_i(p) - \mathcal{L}(q, v)
		H(q, p) = \Leg\qty[\mathcal{L}(q, v)](p) = p \cdot v(p) - \mathcal{L}(q, v)
	} \, .
\end{equation}


Now, in general we have
\begin{equation}
	% dH(q, p, t) = \sum_i \pdv{H}{q_i} dq_i + \pdv{H}{p_i} dp_i + \pdv{H}{t} dt \, .
	dH(q, p, t) = \pdv{H}{q} \cdot dq + \pdv{H}{p} \cdot dp + \pdv{H}{t} dt \, .
\end{equation}
Inserting Eq.~\eqref{eq:hamiltonian_differentiable} here yields:\footnote{We do not use the most general form of the Hamiltonian Eq.~\eqref{eq:hamiltonian_general} because we need $\mathcal{L}$ to be differentiable to be able to calculate $dH$.}
\begin{align}
	dH(q, p, t) &= d (p \cdot v - \mathcal{L}(q, v))
	\notag\\
	&= v \cdot dp + p \cdot dv - d \mathcal{L}(q, v)
	\notag\\
	% &= \sum_i v_i dp_i + p_i dv_i - \pdv{\mathcal{L}}{q_i} dq_i - \pdv{\mathcal{L}}{v_i} dv_i - \pdv{\mathcal{L}}{t} dt
	&= v \cdot dp + p \cdot dv - \pdv{\mathcal{L}}{q} \dot dq - \pdv{\mathcal{L}}{v} \cdot dv - \pdv{\mathcal{L}}{t} dt
	\notag\\
	% &\underset{\text{ELE, Eq. \eqref{eq:ele}}}{=} \sum_i v_i dp_i + p_i dv_i - \dv{p_i}{t} dq_i - p_i dv_i - \pdv{\mathcal{L}}{t} dt
	&\underset{\text{ELE, Eq. \eqref{eq:ele}}}{=} v \cdot dp + p \cdot dv - \dv{p}{t} \cdot dq - p \cdot dv - \pdv{\mathcal{L}}{t} dt
	\notag\\
	% &= \sum_i - \dv{p_i}{t} dq_i + v_i dp_i - \pdv{\mathcal{L}}{t} dt
	&= - \dv{p}{t} \cdot dq + v \cdot dp - \pdv{\mathcal{L}}{t} dt
	\, .
	\notag\\
\end{align}
Comparing this to the general coefficients yields the \Def{Hamilton equations}
\begin{equation}\label{eq:hamilton_eq}
	\eqbox{
		% \pdv{H}{q_i} = - \dv{p_i}{t} = - \dv{\mathcal{L}}{q_i}
		\pdv{H}{q} = - \dv{p}{t} = - \dv{\mathcal{L}}{q}
	}
	\qquad
	\eqbox{
		% \pdv{H}{p_i} = v_i = \dv{q_i}{t}
		\pdv{H}{p} = v = \dv{q}{t}
	}
	\qquad
	\eqbox{
		\pdv{H}{t} = - \pdv{\mathcal{L}}{t}
	} \, .
\end{equation}
Note of course that these are really equations for each component of $q, p$ etc., so overall these are $2S + 1$ equations.

-> this is basically analogue of ELE on the cotangent bundle instead of tangent bundle; just like ELE allowed us to get the curve $q$ for a system in configuration space (thereby also curve in tangent bundle, since we can get $\dot{q}$ from $q$\todo{right?}), i.e.~its evolution in time, we now have a way to determine curve in phase space (= cotangent bundle of configuration space\todo{too much detail?})

% we have ported the theory from (the tangent bundle of the) configuration space to phase space (= cotangent bundle of configuration space)


At this point, let us take a step back and recap what happened in this section. We have derived the Hamiltonian $H$ and corresponding Hamilton equations as analogues of Lagrangian and ELE. But what did we actually gain from that? Well, one of the primary issues with the Lagrangian approach was that the ELE ended up being second-order differential equations. The Hamilton equations, on the other hand, are first order differential equations -- goal achieved. Of course, such an advancement seldomly comes without a price: we have doubled the number of equations to solve. Nevertheless, it is often worth paying this price since the overall complexity of the problem may still be reduced.

-> especially if one of the $q_i$ does not appear in $\mathcal{L}$ (and thus also not in $H$), which is sometimes called \Def{cyclic coordinate}; in that case, there is not one but actually two equations less to solve because Eq.\eqref{eq:hamilton_eq} tells us that $p_i = \text{const}$ too


% -> ok, what this means is that using Hamiltonian is just a reformulation of what we have been able to do anyway; so, what's cool about it, why should we use it? well, one practical issue with Lagrangian is that the general form of equations of motion are second-order differential equations (total time derivative is especially nasty), and (as we will see) by including derivatives directly into the generalized momenta, the Hamiltonian is able to reduce this to first-order differential equations (at the cost of doubling the equations; but this is price we are often absolutely willing to pay, as it still results in overall simplification of the problem)

-> another advantage: Hamiltonian itself corresponds to total energy under certain circumstances \todo{show how}, so unlike Lagrangian it does (can) have a physical meaning

-> also talk about how $\dv{H}{t} = 0$ corresponds to conservation of energy; note that when energy is conserved, one has scleronom constraints, which implies $\pdv{\mathcal{L}}{t} = 0$ and thus by Hamilton equations $\pdv{H}{t} = 0$ as well (less strict criterion than vanishing of total time derivative)



% purpose of Euler-Lagrange equations (ELE) is to give us a way to find $q$ as function of $t$ for a given Lagrangian; when switching to Hamiltonian, this transition would not be complete without a similar way of obtaining $(q, p) \eqqcolon \gamma$ from a given Hamiltonian (be it that we know $H$ straight up, or get it via Legendre from Lagrangian); basically, what we want is turning ELE, i.e.~conditions on derivatives of Lagrangian, into conditions on derivatives of Hamiltonian; fortunately, we can relate Hamiltonian to Lagrangian; it is thus straightforward idea to write out the differential of Hamiltonian and then compare general coefficients to coefficients in terms of the Lagrangian (for the latter, we hope to be able to apply ELE)





		\subsection{Principle Of Least Action}
relate Hamilton principle to principle of least action

\todo{maybe remove?}


\todo{make sure following is mentioned: we can see how Hamilton equation is truly analogue of ELE on phase space by alternative derivation of them; we now vary $\mathcal{L}$ expressed using $q, p, H$ on phase space in same manner that $\mathcal{L}$ was varied on configuration space before, and this yields Hamilton equation}



	% \section{The Mathematical Deep Dive: Symplectic Structure Of Classical Mechanics}
	\section{The Mathematical Deep Dive: Symplectic Structure}

summary of all Wikipedia articles I could find on this:
% - https://en.wikipedia.org/wiki/Hamiltonian_mechanics#From_symplectic_geometry_to_Hamilton's_equations
% - https://en.wikipedia.org/wiki/Hamiltonian_vector_field
% - https://en.wikipedia.org/wiki/Tautological_one-form
% - https://en.wikipedia.org/wiki/Legendre_transformation#Analytical_mechanics
% - https://en.wikipedia.org/wiki/Generalized_coordinates
% - https://en.wikipedia.org/wiki/Canonical_coordinates

Darboux's theorem forms basis for this; states that every symplectic manifold is the phase space of some physical system (is equivalence; every phase space is also symplectic)! So this type of manifolds is really the arena of Hamiltonian mechanics!


idea: we have phase space; at every point in this, I can look at tangent space, and this point-wise mapping induces a tangent bundle

-> there is a natural mapping, given by symplectic form (also: tautological one-form), between tangent and cotangent bundle; and in a small neighborhood of certain point, Darboux guarantees this can be expressed in terms of the canonical coordinates

-> we can then write down a vector field in terms of this (the Hamiltonian vector field), $X_H = J dH$ (sometimes expressed as $J(dH)$), and solving the differential equation for this vector field on the phase space (there is a natural way to formulate this on vector fields) turns out to be nothing but solving the canonical equations (from Hamiltonian) that we have derived (if we also use knowledge from ELE)

-> ah, even better: $X_H$ is defined via $X_H(Y) = dH(Y) \coloneqq \omega_H(X_H, Y)$; this is canonical identification of one-form $\omega_H$ and vector field $X_H$, which are complementary (so $X_H$ is basically dual one to this canonical form $\omega_H$); then it takes form noted above


natural next step: Hamiltonian flow



\hrule

\todo{this is more like statistical physics, right?}


hier halt etwas mathematischere Beschreibung; die kanonischen Vertauschungsrelationen definieren nämlich mathematisch gesehen eine Basis sowie die dazu duale Basis eines Tangentialraums bzw. sogar -bündels

-> Beispiele für symplektische VR sind insbesondere die Tangentialräume von symplektischen MF

-> Satz von Darboux zeigt: jede symplektische MF ist Phasenraum eines physikalischen Systems (habe ich zumindest mal so gelesen)


gute Quelle: Nakahara DiffGeo + Topologie Abschnitt 5.4.3

	\subsection{Phasenraum}
%Die Idee der Klassischen Statistischen Mechanik ist es, ein makroskopisches Vielteilchen-System durch seine klassischen, mikroskopischen Eigenschaften zu beschreiben und die Quantenmechanik erst einmal zu vernachlässigen. Manchmal ist das hilfreich bei der Veranschaulichung, aber man muss immer beachten, dass diese Beschreibung aus verschiedensten Gründen nicht exakt ist.\\
Mathematisch ist ein Teilchen in einem Gebiet $\Omega$ beschreibbar als Phase $\gamma = (\vec{p}, \vec{q})$ bestehend aus den \Def[Koordinaten! generalisierte]{generalisierten Koordinaten} $\vec{p}, \vec{q}$ im zugehörigen \Def{Phasenraum}
\begin{equation}
\Gamma = \mathbb{R}^3 \cross \Omega = \qty{\gamma: \; \gamma = (\vec{p}, \vec{q}) \equiv \text{ Zustand}} \equiv \text{ Zustandsraum} \, ,
\end{equation}
wobei unter Umständen noch Nebenbedingungen berücksichtigt werden müssen.

? eher Konfiguration ? (p,q) ist Zustand statt Konfiguration, wenn stationäres Problem vorliegt. Dann ist ja Zeit egal und kann weggelassen werden (wie bei $\Psi$, das ja meist zeitunabhängig und dann ist eben bereits $\Psi(\vec{r})$ Zustand)

	\anm{meist ist $\vec{q} \in \Omega \subset \mathbb{R}^3$ ein Element des Ortsraumes ($\Omega$ ist natürlich $\subset \mathbb{R}^3$, da dies ja der von uns Menschen beobachtbare Raum ist) und $\vec{p} \in \mathbb{R}^3$ ein Element des Impulsraumes, der den Dualraum zum Ortsraum bildet (anschaulich, da man mit dem Impuls, der die Bewegungsrichtung und -geschwindigkeit enthält, quasi Orte aufeinander abbilden kann, sich also von einem zum anderen bewegen). Der Wechsel zwischen Orts- und Impulsraum ist übrigens mithilfe der Fourier-Trafo möglich.}


Betrachtet man nun $N$ Teilchen in Zuständen $(\vec{p}_i, \vec{q}_i)$, so ist der Phasenraum des Gesamtsystems gerade das kartesische Produkt der einzelnen Phasenräume, also
\begin{equation}
\begin{split}
\Gamma &:= \Gamma_{Ges} = \Gamma_1 \cross \dots \cross \Gamma_N = \qty(\mathbb{R}^3 \cross \Omega) \cross \dots \cross \qty(\mathbb{R}^3 \cross \Omega) = \qty(\mathbb{R}^3 \cross \Omega)^N
\\
&= \qty{\gamma: \; \gamma = \qty((\vec{p_1}, \vec{q_1}), \dots, (\vec{p_n}, \vec{q_n}))} = \qty{\gamma: \, \gamma = \qty(\vec{p_1}, \dots, \vec{p_n}, \vec{q_1}, \dots \vec{q_n})} \, .
\end{split}
\end{equation}
Durch Angabe von $\gamma \in \Gamma$ ist das $N$-Teilchen-System also vollständig beschreibbar.

	\anm{man sieht aber, dass $\dim\qty(\Gamma) = 6N$, was in realen Anwendungen sehr groß werden kann (Avogadro-Zahl ist ja $\approx 6 \cdot 10^{23}$ !), daher ist das nicht immer die beste Möglichkeit (siehe StaPhy).}\\

Oft ändert man nun noch die Indizes, da nicht immer alle drei Teilchenkoordinaten zusammen benötigt werden und schreibt sie in einen Gesamtorts-/ impulsvektor
\begin{align}
p &= (p_{1,1}, p_{1,2}, p_{1,3}, \dots, p_{N,1}, p_{N,2}, p_{N,3}) = (p_1, \dots, p_{3N})
\\
q &= (q_{1,1}, q_{1,2}, q_{1,3}, \dots, q_{N,1}, q_{N,2}, q_{N,3}) = (q_1, \dots, q_{3N})
\\
\Rightarrow \quad \gamma &= (p, q) \in \qty(\mathbb{R}^{3N} \cross \Omega^{N}) = \Gamma \, .
\end{align}

! Beispiel Plot reinmachen von Phasenraum Harmonischer Ossi, da sieht man mögliche (p,q)-Paare zu fester Energie, Masse = Nebenbedingung !



	\subsection{Funktionen auf $\Gamma$}
Ein Beispiel für eine Funktion auf dem Phasenraum ist die Hamilton-Funktion $H$ (wie Hamilton-Operator), die gleichzeitig die Energie beschreibt und definiert ist als
\begin{align}
H: \Gamma \rightarrow \mathbb{R}, \; \gamma \mapsto H(\gamma) = \sum\limits_{i = 1}^N \qty(\frac{\vec{p}^{\;2}_i}{2m} + V_1(\vec{q}_i)) + \sum\limits_{i,j = 1; i \neq j}^N V_2(\vec{q}_i - \vec{q}_j) \, .
%\\
%&= \sum\limits_{j = 1}^{3N} \qty(\frac{p_j^2}{2m} + V_1(q_j)) + \sum\limits_{i,j = 1; i \neq j}^{3N} V_2(\vec{q}_i - \vec{q}_j) .
\end{align}

	\anm{damit das Phasenraumvolumen eines Teilchens endlich ist, braucht man ein Potential, das im Unendlichen divergiert, da es sonst frei beweglich ist und somit ein unendliches Volumen beim Ortsteil eingenommen wird.}



Wie in Vektorräumen üblich, existiert auch in $\Gamma$ noch mehr Struktur und zwar eine Art Skalarprodukt, es hilft hier der Satz von Darboux: er besagt, dass jeder Phasenraum in der Hamilton'schen Mechanik eine \Def[symplektisch! -e Mannigfaltigkeit]{symplektische Mannigfaltigkeit} bildet (Begriffe sind äquivalent). Das ist ein Paar $(M, \omega)$ bestehend aus einer glatten Mannigfaltigkeit $M$ mit einer \Def[symplektisch! -e Differentialform]{symplektischen Differentialform} $\omega = \sum\limits_{i,j} \omega_{ij} \, dq_i \wedge dp_j$ (glatt und geschlossen, also $d\omega = 0$), die analoge Rollen zu Vektorräumen mit alternierenden Bilinearformen/ Skalarprodukten einnehmen.

! siehe OneNote $\rightarrow$ StaPhy Zusammenfassung für sehr hilfreiche Aufgabe ! dazu in Übung 10 MfP angucken, die man $\pdv{x}$ in einer Differentialform auswertet und paar andere coole Sachen ! w anscheinend mit Koeffizienten 1 !

Auf dieser Grundlage kann man die sogenannte \Def{Poisson-Klammer} definieren als
\begin{equation}
\qty{f,g}_{p,q} = \sum\limits_{i = 1}^{3N} \pdv{f}{q_i} \pdv{g}{p_i} - \pdv{f}{p_i} \pdv{g}{q_i} = \sum\limits_{i,j} \omega^{ij} \, \partial_i f \, \partial_j g \, ,
\end{equation}
das gilt nur in gewählten Koordinaten !!! ? hatte vorher 6N, aber das kann nicht sein oder ? -> dort wahrscheinlich mit symplektischer Matrix gearbeitet

wobei die Indizes $p,q$ oft weggelassen werden, da sie die Basis kennzeichnen und die Auswertung basisunabhängig ist (folgt aus den Eigenschaften von Differentialformen).

Es lassen sich direkt einige grundlegende Relationen nachrechnen, die \Def[Poisson-Klammer! fundamentale]{fundamentalen Poisson-Klammern}:
\begin{equation}
\{q_k, q_l\} = 0 \hspace{1cm} \{p_k, p_l\} = 0 \hspace{1cm} \{q_k, p_l\} = \delta_{kl} \, .
\end{equation}

Dabei muss man lediglich die folgenden Zusammenhänge ausnutzen:
\begin{equation}
\pdv{q_k}{q_l} = \delta_{kl} = \pdv{p_k}{p_l} \hspace{2cm} \pdv{q_k}{p_l} = 0 = \pdv{p_k}{q_l} .
\end{equation}

Man kann nun zeigen, dass für eine beliebige Phasenraumfunktion $F(p,q)$ gilt:
\begin{equation}
\dv{F}{t} = \qty{F,H} + \pdv{F}{t} .
\end{equation}

Um nun die Dynamik dieses Systems (Annahme: $N$ Teilchen gleicher Masse $m$) zu beschreiben, kann man einfach die generalisierten Orts- und Impulsfunktionen $p_i, q_i$ (ordnen ja letztendlich jedem Zustand $\gamma \in \Gamma$ gewisse Größen zu, sind gerade Phasenraumfunktionen; sind nicht explizit zeitabhängig) in die Poisson-Klammer einsetzen. Das Ergebnis sind die \Def[kanonisch! -e Bewegungsgleichungen]{Hamilton'schen/ kanonischen Bewegungsgleichungen}:
\begin{equation}\label{eq:kanGl}
\dot{q}_i = \qty{q_i, H} = \pdv{H}{p_i} \qquad \dot{p}_i = \qty{p_i, H} = -\pdv{H}{q_i}, \qquad i = 1, \dots, 3N \, .
\end{equation}



	\subsection{Zeitentwicklung}
Die allgemeine Lösung der kanonischen Gleichungen \eqref{eq:kanGl} zum beliebigen Anfangswert $\gamma$ beschreibt ja die Zeitentwicklung eines Systems, ordnet also jedem Zeitpunkt $t$ einen Punkt $\gamma(t) = \tilde{\gamma} = (p,q) \in \Gamma$ zu und bildet somit eine Kurve im Phasenraum (was einer Abfolge von Systemzuständen zu verschiedenen Zeiten entspricht).\\
Diese allgemeine Lösung lässt sich zu beliebigen Startwerten bestimmen (zumindest theoretisch ist das möglich, hier aber gar nicht explizit nötig) und ist deshalb allgemein mithilfe einer Abbildungs-Schar darstellbar, dem \Def[Hamilton-Fluss]{Hamilton'schen Fluss}
\begin{equation}
\mathcal{F}_t : \Gamma \rightarrow \Gamma, \; \gamma \mapsto \mathcal{F}_t \gamma \equiv \gamma(t) \, .
\end{equation}
Es folgen quasi per Definition die Eigenschaften $\mathcal{F}_0 \gamma = \gamma$, $\mathcal{F}_s \circ \mathcal{F}_t = \mathcal{F}_{s+t}, \, s,t \in \mathbb{R}$.

Benutzung Fluss ergibt hier voll Sinn, weil man so zu jedem Anfangszustand die komplette Zeitentwicklung beschreiben kann und das in einer Abbildung (fasse also den Parameter der Schar als Parameter einer Abbildung auf)
\begin{equation}
\mathcal{F}: (\mathbb{R}, \Gamma) \rightarrow \Gamma, \; (t, \gamma) \mapsto \gamma(t)
\end{equation}

	\anm{wir nehmen an, dass am Rand des Gebietes $\Omega$ die Lösung weiter gültig bleibt, das Teilchen aber $"$reflektiert$"$ bzw. $"$gespiegelt$"$ wird: $(\vec{p}_i, \vec{q}_i) \mapsto (-\vec{p}_i, \vec{q}_i)$.}\\

Vorgriff zur Statistischen Mechanik: hier beschreibt man den Zustand bzw. die Präparation von Systemen als Dichtefunktion $\rho$ (kommt z.B. aus mikrokanonischer/ kanonischer Gesamtheit), so ist dort die Zeitentwicklung des Systems gegeben durch:
\begin{equation}
\dot{\rho}_t = \qty{\rho, H} \, .
\end{equation}
Dies ist die \Def{Liouville-Gleichung}, die dem Schrödinger-Bild $\dot{\rho}_t = i [\rho, H]$ in der QM entspricht. Der Zusammenhang zum Hamilton'schen Fluss $\mathcal{F}_t$ ist $\rho_t(\gamma) = \rho\qty(\mathcal{F}_{-t} \gamma)$.\\

Will man nun ein Volumen oder eine Fläche messen, so ist dazu immer ein Maß nötig. Das auf $\Gamma$ verwendete Liouville-Maß ist dabei wie das Lebesgue-Maß definiert:
\begin{equation}
d\gamma = d^{\,3N}p \, d^{\,3N}q = dp_1 \, dq_1 \dots dp_{3N} \, dq_{3N} \equiv d^{\,3N}p \wedge d^{\,3N}q \, .
\end{equation}

Mit diesem Hilfsmittel kann man nun die beiden wesentlichen Erhaltungsgrößen im Phasenraum mit den zugehörigen Konsequenzen untersuchen, Volumen und Energie.

Die Erhaltung des Volumens (damit ist nicht die Erhaltung von $d\gamma$ gemeint, sondern des Integrals davon über eine Menge $M$ !) bedeutet einfach, dass für eine beliebige integrierbare Funktion $f$ zu jedem Zeitpunkt $t \in \mathbb{R}$ gilt:
\begin{equation}\label{eq:zeitentw}
\int_M f\qty(\mathcal{F}_t \gamma) \, d\gamma = \int_{\mathcal{F}_t^{-1} M} f\qty(\gamma) \, d\gamma = \int_M f(\gamma) \, d\gamma \, .
\end{equation}

Idee: Anwendung der Transformationsformel auf die linke Seite, das ergibt dann $f\qty(\mathcal{F}_t^{-1}(\mathcal{F}_t \gamma)) = f(\gamma)$, aber auch auf Gebiet nötig, es kommt dann $\mathcal{F}_t^{-1}M$ raus

%-> müsste links nicht auch $d\mathcal{F}_t \gamma$ stehen ??? evtl nicht, da wir ja über gleiche kurve integrieren (?)

Daraus erhält man dann mit $f = \chi_M: \Gamma \rightarrow [0,1]$ als charakteristische Funktion einer beliebigen Menge $M \subset \Gamma$ für die Volumina
%\begin{equation}
%V_{\mathcal{F}_t^{-1}M} = \int f\qty(\mathcal{F}_t \gamma) \, d\gamma %= \int f(\gamma) \, d\gamma = V_M
%\end{equation}
\begin{equation}
\int_{\mathcal{F}_t^{-1} M} d\gamma = \int_M d\gamma  \equiv \int_M \omega^{3N} \Leftrightarrow V_M = V_{\mathcal{F}_t^{-1}M} \, .
\end{equation}
Anmerkung: $\omega^{3N}$ ist gerade das $\omega$ von oben mit mehr Dimensionen (evtl. nur $\omega^N$)

(sicher -1 etc. ??? $\rightarrow$ ja, jetzt eigentlich schon; das kann man zudem safe umschreiben zu $\mathcal{F}_{-t}$ nach den Eigenschaften von Flüssen)

$\Rightarrow$ evtl. ist Bezeichnung nur missverständlich; er schreibt $\mathcal{F}_t^{-1}M = \{\gamma: \mathcal{F}_t \gamma \in M\}$, vlt. ist also gemeint, dass man sich das Volumen der zeitentwickelten $\gamma$ anschaut und wenn man das dann quasi zurückentwickelt, erhält man das gleiche Volumen wie von $M$ ? Das heißt nicht, dass gleich viele Zustände oder so (heißt es das doch evtl. ? Haben hier noch gar keine Dichte; eigentlich Aussage ist doch, dass Zustände aus $M$ auch bei Zeitentwicklung in $M$ bleiben oder ?), sondern eben nur, dass von allen Zuständen multipliziert mit der Dichte das gleiche Volumen eingenommen wird.
-> hier geht es tatsächlich einfach nur mit Transformationsformel

Wie so oft in der Physik wird (hier auch auf Grundlage des 1. Hauptsatzes -> we are at interface of mechanics and thermodynamics here!) zudem die Energieerhaltung angenommen, es soll während der Zeitentwicklung nichts davon verloren gehen. Das bedeutet einfach
\begin{equation}
H(\mathcal{F}_t \gamma) = H(\gamma), \, \forall t \, .
\end{equation}
Betrachtet man nun alle Punkte mit gleicher Energie $E$, so bilden diese eine Energiefläche $\qty{\gamma | \, H(\gamma) = E}$, die als Fläche im $6N$-dimensionalen Phasenraum genau $(6N-1)$-dimensional ist. Das heißt aber, dass sie ein Liouville-Maß von 0 haben !

Um trotzdem eine Aussage über Energieflächen treffen zu können, fügt man ihnen in der fehlenden Dimension die Ausdehnung $\epsilon$ hinzu und konstruiert so eine Energieschale $\qty{\gamma: \; E-\epsilon \leq H(\gamma) \leq E}$, die nun Liouville-messbar ist mit Maß $\neq 0$.\\
Um diese kleine Schummelei auszugleichen, teilen wir bei der Definition des Flächenintegrals über eine Energiefläche (oder einer Teilmenge davon) wieder durch $\epsilon$ und erhalten so als Integral einer beliebigen Funktion $f: \Gamma \rightarrow \mathbb{R}$ (z.B. eine Observable) 
\begin{align}\label{eq:energy}
\expval{f}_{\qty[E = H(\gamma), \, E + \epsilon]} &= \int \chi_{\qty[E = H(\gamma), E - \epsilon]} f(\gamma) \, d\gamma
\notag\\
&= \int_{\qty{\gamma | \, H(\gamma) = E}} f(\gamma) \, d\gamma = \int \delta(H(\gamma) - E) \, f(\gamma) \, d\gamma
\notag\\
&:= \lim_{\epsilon \rightarrow 0} \frac{1}{\epsilon} \int_{E-\epsilon \leq H(\gamma) \leq E} f(\gamma) \, d\gamma = \dv{E} \int_{H(\gamma) \leq E} f(\gamma) \, d\gamma \, .
\end{align}

-> müsste es nicht nur über $H(\gamma) = E$ sein, da $\epsilon = 0$, also $E - \epsilon = E$; zweite Schreibweise überhaupt nötig ???


Nach \eqref{eq:zeitentw} ist auch dieses Integral zeitunabhängig, jedoch hängen die Schalenbreite und somit der Wert des Integrals vom Inversen des Gradienten der Energie $dE$ ab.

Anmerkung: wir können die $p_i, q_i$ auf einer Energiefläche nicht beliebig groß machen, da sonst zu viel Energie dazu benötigt wird (haben aber nur konstant viel zur Verfügung)\\

Die hier Beschreibung eines Systems über eine Phase $\gamma \in \Gamma$ ist meistens jedoch überhaupt nicht praktisch, da $\Gamma$ ja $6N$-dimensional ist und $N$ oft Werte im Bereich von $10^{23}$ hat - man könnte die nötigen Datenmengen nicht speichern, geschweige denn damit rechnen. Zudem wäre es aufgrund der Quantenmechanik gar nicht möglich, ein System genau zu vermessen oder in einer Phase $\gamma$ zu präparieren.

Wie bereits ganz am Anfang angedeutet, ist es sinnvoll, auf eine nicht exakte, statistische Beschreibung zurückzugreifen, da eine genaue nicht funktioniert. Die klassische Vielteilchen-Mechanik ist also eine Statistische Mechanik.



		\subsection{Random Ergänzungen}

kanonische Trafos sind Basiswechsel (bzw. eigentlich sogar Kartenwechsel oder ?) -> jo, Karten- und Basiswechsel sind ja quasi das Gleiche; deshalb auch ruhig Interpretation als symplektische MF bringen in Kapitel nach Hamilton, da sieht man dann mathematisch genau die Physik von vorher wieder

Liouville-Gleichung folgt, weil $\rho$ Erhaltungsgröße quasi (haben $\dv{\rho}{t} = 0$ und dann Umstellen)

Nolting Band 6, Abschnitt 1.2.1 - 1.2.3 ist super zu Phasenraum !


haben auch Poisson-Klammern bei Drehimpuls (werden auf jeden Fall auf Seite 5, Band 5.2 erwähnt, sehen aber genau so aus wie die Kommutatorrelationen) !



Formulierung mit Mannigfaltigkeiten: $(q,\dot{q}) \equiv$ Punkt, Tangentialvektor ergibt Sinn als Basis des Tangentialbündels (das den Konfigurationsraum beschreibt) -> ist ja bis auf Faktor $m$ gleich mit $(q, p)$ !! Und dann ist auch $(q,p)$ als Basis des Kotangentialbündels richtig/ sinnvoll (weil wegen Trivialisierung right; Eselsbrücke: Impuls erzeugt Translationen/ Bewegung, also die Abbildung eines Punktes auf andere Punkte und ist daher was Duales)



die ganz allgemeine Form von Lagrange- und Hamilton-Formalismus ist das Wirkungsprinzip -> da dann auch guter Verweis möglich, dass GR den gleichen Lagrangian hat und nur andere Metrik, da die dort durch Gravitation und Massen beeinflußt wird (daher dann auch bisschen andere Physik)

Legendre-Trafo wechselt zwischen Tangential- und Kotangentialbündel oder?


\end{document}