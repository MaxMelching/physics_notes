\documentclass[../class_mech_main.tex]{subfiles}
%\input{../header} \graphicspath{../}


\begin{document}


% \chapter{Erweiterungen von Newton}
\chapter{Analytical Mechanics}

Newtonian mechanics provided a description of the world in terms of forces and momenta. This is convenient for many applications, but not for all. Sometimes, it is more beneficial to adopt different viewpoints on the physical world, and we present several alternative frameworks in this chapter. These are often summarized under the term \enquote{analytical mechanics}. Two well-known branches of this are the Lagrangian and the Hamiltonian one.


% -> maybe say that we switch to fields (?) and generalized coordinates + momenta


-> Lagrange and Hamiltonian approach things in terms of energy (yes, Lagrange as well; $\mathcal{L} = T - V$ in many cases) -> conceptually different, but also mathematically because this means we mainly work with scalars from now on! Not vectors anymore



	\section{Constraints \& Setup}
In many cases, physical objects are not free to evolve in the presence of forces, but instead subject to certain \Def{constraints}. Easy examples are balls attached to some rigid rod, i.e.~basically a pendulum. This ball is free not to move in all spatial dimensions, but must always maintain a fixed distance from the pendulum's pivot since it is attached to the rod -- this is a constraint. In Newtonian terms, this manifests as a \Def{constraint force} $\vec{C}$ exerted by the rod.


As part of the description of systems in presence of constraint forces, it will turn out beneficial to not just formulate statements in terms of the spatial position $\vec{x}$ of a particle. Instead, \Def{generalized coordinates} $q$ are used from now on;\footnote{Note that we choose to omit the arrow above $q$ here. The reason is that, as we will see later, $q$ can be interpreted as a point on a manifold. Unlike in Euclidean space, this is now a distinct notion from vectors, which cannot be interpreted in terms of position vectors.} these can have the components $x_i$ in each component $q_j$, but this need not be the case. Accordingly, one defines the \Def{generalized velocity} as $v = \dot{q} = \dv{q}{t}$. The use of enables a more flexible choice of coordinates, something that we will quickly learn to appreciate over the course of next sections. Basically the only requirement on the $q_j$ is that we can express the particle positions in terms of the generalized coordinates, $\vec{x} = \vec{x}(q_1, \dots, q_S)$ must be possible $\forall i$.



\begin{table}
	% \definecolor{namecellcolor}{named}{gray!30}
	% \colorlet{namecellcolor}{gray!30}
	\colorlet{namecellcolor}{white}
	\centering
	\begin{tabular}{cc}
		\toprule
		\toprule
		% 
		\cellcolor{namecellcolor} holonomic & $\eqbox{f = 0}$ or some expression $g$ with $dg = 0$
		\\
		\midrule
		\cellcolor{namecellcolor} \multirow{2}{*}{non-holonomic} & e.g., $\eqbox{f \geq 0}$ or $\eqbox{a \leq f \leq b}$
		\\
		 & or some expression $g$ with $dg \neq 0$
		\\
		\midrule
		\cellcolor{namecellcolor} scleronomic & not time dependent
		\\
		\midrule
		\cellcolor{namecellcolor} rheonomic & time dependent
		\\
		\bottomrule
		\bottomrule
	\end{tabular}
	
	\caption{Different types of constraints. We use $f$ to denote functions, and $g$ to denote expressions. The latter includes differentials $dq_j, dt$ (so the Pfaffian form discussed below falls into this category), functions do not (though this is not \enquote{official terminology}, just introduced for this table).}
	\label{tab:constraint_types}
\end{table}



With the relevant set of coordinates in place, we can go on to study functions of the $q_j$, such as constraints. Many different types of constraints exist. A rough classification is provided in Tab.~\ref{tab:constraint_types}. Most of the ones that are typically encountered in physics classes are \Def[constraint!holonomic]{holonomic} in nature, i.e.~they can be given as an equation of the form
\begin{equation}\label{eq:holonomic_constraint}
	\eqbox{
		f(q, t) = 0
	} \, .
\end{equation}
An important part of this definition is the independence of $\dot{q}$, i.e.~$\pdv{f}{\dot{q}} = 0$.


Any constraint that cannot be expressed as Eq.~\eqref{eq:holonomic_constraint} are called \Def[constraint!non-holonomic]{non-holonomic constraints}. They can come in various shapes and forms, e.g., inequalities or $f = 0$ with a function $f$ that contains derivatives of $q$ in addition to $q, t$.


Another type of classification includes the (in-)dependence (of) on time of the constraint: if none is present, it is called \Def{scleronomic}, and if one is present, the name is \Def{rheonomic}.\\


To end this section, here is a note that did not really fit anywhere else: Systems comprised entirely of non-holonomic, holonomic constraints are also called \Def[system!holonomic]{holonomic}, \Def[system!non-holonomic]{non-holonomic systems}, respectively.



			\paragraph{Pfaffian Form}
For reasons we do not understand at the moment, constraints of the form
\begin{equation}\label{eq:pfaffian_constraint}
	\eqbox{\sum_{i = 1}^{S} f_i dx_i + f_t dt}
	\ \hat{=} \
	\eqbox{
		\sum_{j = 1}^S a_j dq_j + b_t dt = 0
	}
\end{equation}
will play a prominent role in our analyses (these are referred to as \enquote{expression} in Tab.~\ref{tab:constraint_types}). Therefore, it is worthwhile to study how they relate to different types of constraints, especially holonomic and non-holonomic ones.

Holonomic constraints can always be brought into this form (even if they are not already given in it), and one can actually see that fairly easily. All we have to do is differentiate $f = 0$, which yields:
\begin{equation}
	0 = df = \sum_{j = 1}^S \pdv{f}{q_j} dq_j + \pdv{f}{t} dt \eqqcolon \sum_{j = 1}^S a_j dq_j + b_t dt
	\quad \Leftrightarrow \quad
	\eqbox{
		a_j = \pdv{f}{q_j}, \; b_t = \pdv{f}{t}
	} \, .
\end{equation}
In the same manner, we could obtain the constraint in terms of $dx_i, dt$.


For non-holonomic constraints, there is no general form in which they are given, but sometimes it is the Pfaffian one. This poses an interesting question: given an equation of the form \eqref{eq:pfaffian_constraint}, how can I see which type of constraint this belongs to? The answer is surprisingly easy (because there is a theorem for this, the Poincare lemma): for the given expression $g = 0$ involving differentials, calculate $dg$. If $dg = 0$, a function with $g = df$ exists, i.e.~$g = 0$ has been obtained from another equation of the form $f = 0$, implying that the corresponding constraint is holonomic; for $dg \neq 0$, the constraint is non-holonomic. This motivates the label \enquote{non-integrable} for non-holonomic constraints.



	\section{Lagrange-Formalism}
If we now envision more complex systems, where many such constraints are present, things quickly becomes hard too handle from the Newtonian point of view. This is why other approaches to mechanics are worthwhile exploring, founded on different principles than simply deriving an equation of motion straight from Newton's second law.


% Before showing how this can be done, we will present the general setup assumed henceforth: there are $N$ particles, each described by a position $\vec{x}_i$, i.e.~in total $3 N$ degrees of freedom. One of the first major changes compared to Newtonian physics is the type of coordinates used. Instead of restricting ourselves to the actual, spatial positions $\vec{x}$ of the physical system we wish to describe, it turns out to be beneficial to work with \Def{generalized coordinates} $q$.\footnote{Note that we choose to omit the arrow above $q$ here. The reason is that, as we will see later, $q$ can be interpreted as a point on a manifold. Unlike in Euclidean space, this is now a distinct notion from vectors, which cannot be interpreted in terms of position vectors.} Accordingly, one defines the \Def{generalized velocity} as $v = \dot{q} = \dv{q}{t}$.
% 
% Depending on the number of (holonomic) constraints $p$, $S = 3 N - p$ generalized coordinates are needed to describe the system. One requirement on them is that we can express the particle positions in terms of the generalized coordinates, $\vec{x} = \vec{x}(q_1, \dots, q_S)$ must be possible $\forall i$.


Before showing how this can be done, we will present the general setup assumed henceforth: there are $N$ particles, each described by a position $\vec{x}_i$, i.e.~in total $3 N$ degrees of freedom. Depending on the number and type of constraints, the number $S$ of generalized coordinates $q_j$ needed to describe the system can be $\leq 3N$.



		\subsection{D'Alembert's Principle}
% -- Awesome for basic idea: https://en.wikipedia.org/wiki/Virtual_work#Overview

Say we have a particle moving with forces acting on it, so that one can compute the work done by these forces along the trajectory $\vec{x}(t)$. The \Def{principle of virtual work} states that for the path that the particle actually takes, the work remains unchanged upon small variations of this path (unchanged to first order).\footnote{This can be regarded as an application of the principle of least action, that we will encounter later.} This is a variational principle, that can be formalized in the equation
\begin{equation}\label{eq:principle_virtual_work_basic}
	\eqbox{
		\delta W = \vec{F} \cdot \delta \vec{x} = 0
	} \, .
\end{equation}
$\delta W$ denotes the \Def{virtual work} done upon the \Def{virtual displacement} $\delta \vec{x}$ from the particle's path. These virtual displacements should not be thought of as \enquote{real} displacements in space, as they happen instantaneously.
% \todo{is that reason why we have no integral here over $t$? Hmm no, don't think so, integral over $t$ would appear if we had $\vec{F} \cdot \vec{v}$ here... So actually we are kind of lacking an integral over path here...}

The contribution by d'Alembert was to recognize that not only does the force on the particle get contributions from net external forces, which we denote by $\vec{K}$ here, and from the net force $\vec{C}$ arising from the constraints on the system, but also from the inertial force $- \dv{\vec{p}}{t} \underset{m = \text{const}}{=} - m \vec{a}$ that is required to change the particle's state of motion.
% \footnote{This inertial force is essentially a fictitious force arising from an analysis in the rest frame of the moving body.}
\footnote{Essentially, we take the right hand side of Newton's law $\vec{K} + \vec{Z} = m \vec{a}$ and adopt the viewpoint that it is a force as well, so that we effectively analyze a system in equilibrium, namely $\vec{F} = 0$. This is also called a dynamical equilibrium because the particle is not necessarily static. In some sense, this means we perform an analysis from the rest frame of the particle (where it is seen to be in equilibrium), where the inertial force arises as a fictitious forces in this frame.}
Newton's second law immediately tells us that, if we include these inertial forces, $\vec{F} = 0$ so that $\delta W = 0$ holds trivially. However, since $\delta W$ contains the inner product of $\vec{C}$ and $\delta \vec{x}$, by selecting a virtual displacement that is consistent with the constraints (e.g., if the constraint is motion along a circle, we choose a displacement tangential to the circle), the principle of virtual work yields
\begin{equation}
	\delta W = \qty(\vec{K} - m \vec{a}) \dot \delta \vec{x} = 0
\end{equation}
where we have assumed $m = \text{const}$ for simplicity. This is an equation where the constraint forces are eliminated entirely -- something that was not possible when working with Newton's second law.\footnote{Notice how this required a paradigm shift. We are now approaching the situation thinking about energy rather than forces. Of course, forces are still involved in the analysis, but only due to their relation to the work done on the system, which is now the origin of the analysis.}

% -> idea is: we have more forces acting than just the inertial forces, namely also force from constraint, which makes Newtons equations really complicated; we can also write down work done by these forces upon some virtual displacement; the key is now that constraint forces do no work -- they drop out of this equation!!!


The generalization to $N$ particles is straightforward, and the principle of virtual work for this situation becomes
\begin{equation}\label{eq:principle_virtual_work_general}
	\eqbox{
		\delta W = - \sum_i \vec{F}_i \cdot \delta \vec{x}_i = 0 = - \sum_j (Q_j + Q^*_j) \delta q_j = - (Q + Q^*) \cdot \delta q
	} \, ,
\end{equation}
still assuming virtual displacements $\delta \vec{x}_i, \delta q$ consistent with the constraints. Note that the sums have different number of terms here, over $j$ goes up to $S$ and over $i$ up to $3N$. At this point, we are starting to write equations in terms of the generalized coordinates $q$, and this requires the definition of an according \Def{generalized force}
\begin{equation}
	\eqbox{
		Q_j = \sum_i \vec{K}_i \cdot \dv{\vec{x}_i}{q_j}
	} \, .
\end{equation}
Similarly, $Q^*$ is the \Def{generalized inertial force}. It is common to rewrite it in terms of the total kinetic energy $T = \sum_i \frac{1}{2} m_i \vec{x}_i \cdot \vec{x}_i$ of the particles as
\begin{equation}
	Q^* = \sum_j \dv{t} \pdv{T}{\dot{q}_j} - \pdv{T}{q_j}
	\, .
\end{equation}
\enquote{Why?}, you may ask. Well, the reason is that this yields equations that resemble the results obtained from Hamilton's principle, which is treated in the next section.

This means Eq.~\eqref{eq:principle_virtual_work_general} can be recast into
\begin{equation}\label{eq:principle_virtual_work_general_v2}
	\eqbox{
		\sum_j \qty[\dv{t} \pdv{T}{\dot{q}_j} - \pdv{T}{q_j} - Q_j] \delta q_j = 0
	} \, ,
\end{equation}
which forms something like a generalized equation of motion.


Unfortunately, we cannot get rid of the sum over $j$ in Eq.~\eqref{eq:principle_virtual_work_general_v2} in general. For this to be possible, the displacements $\delta q_j$ must be linearly independent (while still being consistent with the constraints), which in turn requires independence of the generalized coordinates $q_j$. This, however, is highly dependent on the problem itself, in particular the type of constraints that are present. If the assumption of independent $\delta q_j$ is justified, Eq.~\eqref{eq:principle_virtual_work_general_v2} can be turned into $S$ equations
\begin{equation}\label{eq:principle_virtual_work_general_simplified}
	\eqbox{
		\dv{t} \pdv{T}{\dot{q}_j} - \pdv{T}{q_j} = Q_j
	} \, .
\end{equation}


% In the rest of this section, we will first show that Eq.~\eqref{eq:principle_virtual_work_general_v2} is just Newton's second law in disguise, and then analyze what happens to the most general result Eq.~\eqref{eq:principle_virtual_work_general_v2} if certain additional assumptions about the system can be made.
% \begin{ex}[Relation to Newtonian Mechanics]
% 	no constraints means we can choose simplified Eq.~\eqref{eq:principle_virtual_work_general_simplified}; we assume conservative force for now; choose generalized coordinates as positions...


% 	-> we get second law
% \end{ex}

In the rest of this section, we will analyze what happens to the most general result Eq.~\eqref{eq:principle_virtual_work_general_v2} if certain additional assumptions about the system can be made. For instance, we will discuss when Eq.~\eqref{eq:principle_virtual_work_general_simplified} may be used.



			\paragraph{Holonomic Constraints vs.~Non-holonomic Constraints}
There are crucial differences in how holonomic and non-holonomic constraints impact our analysis of a system. $p$ holonomic constraints imply $S = 3N - p$, they truly reduce the number of degrees of freedom in a system. For non-holonomic systems this is not the case; while they constrain the system in a certain manner, this restriction is not in a way that a whole degree of freedom is removed. The distance can perhaps best be seen from an example: when working in a 2D space, requiring motion \emph{on} a circle is a holonomic constraint (the radial degree of freedom is removed, only angular one remains), while motion \emph{in} a circle maintains both radial and angular degree of freedom (although it is still clearly constraining the motion).


% An important consequence of this concerns the simplification that led to Eq.~\eqref{eq:principle_virtual_work_general_simplified}. For this, we had to assume independence of the $\delta q_j$ and that they respect the constraints. When system is holonomic, one can always find generalized coordinates that fulfill both conditions. As soon as non-holonomic constraints are present, making sure these constraint forces are respected can become much harder (even for some holonomic ones this may be the case).
An important consequence of this concerns the simplification that led to Eq.~\eqref{eq:principle_virtual_work_general_simplified}. For this, we had to assume independence of the $\delta q_j$ and that they respect the constraints. When we manage to find $q_j$ that respect the constraints in a holonomic system, these are automatically linearly independent (because the number of coordinates we choose, $S = 3N - p$, precisely matches the number of degrees of freedom that the system has if $p$ holonomic constraints are imposed). We explore an alternative way to handle situations where respecting the constraint forces may not be possible, which is frequently the case as soon as non-holonomic constraints are present, but can also occur for certain holonomic ones.


\todo{Wikipedia says Lagrangian approach can only treat holonomic constraints... Check again in which way this is meant (I mean d'Alembert can do non-holonomic, right?)}


% -> constraints relate coordinates, thus something like $f = 0$ is capable of reducing degrees of freedom of a system


% -> basically, through suitable choice of generalized coordinates, we automatically make sure constraints are respected (would usually not be possible for positions; that is how constraints drop out in analytical mechanics, but not Newtonian)



-> no general solution exists for non-holonomic systems! How could we give it, includes so many potential types of constraints, no mathematical properties to exploit


-> non-holonomic are often not only expressable on configuration space; this is why ELE do not work in that case, need Lagrange of first kind



			\paragraph{Holonomic Constraints, Conservative Forces}
The simplified form simplified form from holonomic is already great, but with conservative forces we can do even more


here we have $\vec{K} = - \nabla V$ for some potential $V = V(\vec{x}) = V(q)$, which implies $Q_j = - \pdv{V}{q_i}$. in that case, we can rearrange stuff and obtain the \Def[Lagrange equations!second kind]{Lagrange equations of second kind}
\begin{equation}\label{eq:ele}
	\eqbox{
		\dv{t} \pdv{\mathcal{L}}{\dot{q}_j} - \pdv{\mathcal{L}}{q_j} = 0
	} \, ,
\end{equation}
also called \Def{Euler-Lagrange equations} (ELEs).


-> $V$ does not explicitly depend on $\dot{q}_i$, while $T$ does not explicitly depend on $q_i$


now we will show that Eq.~\eqref{eq:principle_virtual_work_general_v2} is just Newton's second law in disguise, 
\begin{ex}[Relation to Newtonian Mechanics]
	no constraints means we can choose simplified Eq.~\eqref{eq:principle_virtual_work_general_simplified}; we assume conservative force for now; choose generalized coordinates as positions...


	-> we get second law
\end{ex}



			\paragraph{Holonomic Constraints, Non-Conservative Forces}
Eq.~\eqref{eq:principle_virtual_work_general_simplified} is already nice, but through some tricks we can preserve the form of the ELE even for non-conservative forces.

While no potential $V$ with $Q_j = - \pdv{V}{q_i}$ exists in that case, it is possible to define a quantity that plays an analogous for the purpose of Lagrangian, i.e.~a \Def[potential!generalized]{generalized potential} $U = U(q, \dot{q}, t)$ with
\begin{equation}\label{eq:generalized_potential}
	\eqbox{
		Q_j = \dv{t} \pdv{U}{\dot{q}_j} - \pdv{U}{q_j}
	} \, .
\end{equation}
Using this function, Eq.~\eqref{eq:principle_virtual_work_general_simplified} still reads like the ELE \eqref{eq:ele}, just with a modified Lagrangian $\mathcal{L} = T - U$. Also note how a $U$ that does not depend on $\dot{q}$ (one of the defining equations for $V$) turns into a \enquote{normal} potential $V$, which justifies the name \enquote{generalized potential}.


The fact that the ELEs are the equations of motion of systems for both the conservative and non-conservative force case means that holonomic systems can indeed be described entirely in terms of energy. Forces only appear indirectly, in the definition of potential, but are not the quantity of interest anymore in formulating equations of motion (unlike in Newtonian case).



			\paragraph{Non-Holonomic Constraints}
Note that we will not distinguish between the cases of conservative, non-conservative forces because the Lagrangian $\mathcal{L}$ is defined for both cases, so we can just stick to this function $\mathcal{L}$.


It was already mentioned how one issue with non-holonomic constraints was that they do not remove a degree of freedom from the system, which makes a general treatment impossible. In particular, Eq.~\eqref{eq:principle_virtual_work_general} does usually not hold because it can be very challenging to find generalized coordinates consistent with the constraints. To avoid cumbersome searches for $q_j$ that fulfill this condition, we can also choose to go another route and drop this assumption, instead incorporating them into the equations of motion. On paper, this is a step back from what we achieved in this section, but that is better than having nothing on hand to tackle this type of problems.

Trouble with non-holonomic constraints comes, at least partly, from the fact we may not be able to find expressions for the constraint forces $\vec{C}_i$ (so we cannot even verify whether a displacement is indeed consistent with them...). In order to make sure such difficulties are not encountered, in the following we must assume that the every constraint on the system has a Pfaffian form
\begin{equation*}
	\sum_{j = 1}^S a_j dq_j + b_t dt = 0
	\, .
\end{equation*}
Since holonomic constraints always have a Pfaffian form, the method we now present also works for them, which can be useful because they too might create scenarios where generalized coordinates are hard to find explicitly.

Given such Pfaffian forms, the following trick can be applied: replace infinitesimal displacements by virtual displacements, i.e.~$d \mapsto \delta$, recall that $\delta t = 0$, and then recognize that this turns the Pfaffian form into the conditions
\begin{equation}\label{eq:pfaffian_deltas}
	\eqbox{
		\sum_{j = 1}^S a_{mj} \delta q_j = 0
	}
\end{equation}
for each constraint (now labeled with an index $m = 1, \dots, p$). By assigning a Lagrange multiplier $\lambda_m$ to each of them, and noting that Eq.~\eqref{eq:pfaffian_deltas} implies
\begin{equation}\label{eq:pfaffian_deltas_as_work}
	\sum_{m = 1}^p \lambda_m \sum_{j = 1}^S a_{mj} \delta q_j = 0
	\, ,
\end{equation}
we can treat constraints in a well-defined mathematical manner. Using the mathematical theory of how to optimize a function subject to constraints, we can simply add these terms to the Lagrange equations of second kind, turning them into the \Def[Lagrange equations!first kind]{Lagrange equations of first kind}
\begin{equation}\label{eq:lagrange_first_kind}
	\eqbox{
		\dv{t} \pdv{\mathcal{L}}{\dot{q}_j} - \pdv{\mathcal{L}}{q_j} = \sum_{m = 1}^p \lambda_m a_{mj}
	} \, .
\end{equation}
Thus, even in case of non-holonomic constraints, it is possible to obtain results that look very much like the ELEs, with small modifications on top. While on paper, this looks like we are trying to solve for $S + p$ unknown variables (in case of no holonomic, $p$ non-holonomic constraints), this is not actually the case. The idea is to solve each of the $p$ constraint equations in Pfaffian form along with the equations of motion; and while it is true that the constraint equations themselves are not sufficient to account for the additional $p$ degrees of freedom, the fact that they are now also mingled into the the Lagrange equations of first kind explains how it is possible to solve for all $S + p$ constraints.\\


We could just accept that there is mathematical theory for this, but with a little bit of physical intuition we can intuitively understand how the Lagrange equations of first kind may be obtained. Eq.~\eqref{eq:pfaffian_deltas} does look reminiscent of the work done by the constraint force that a single constraint exerts on the system of particles. The total work done by constraint forces would then be given by
\begin{equation}
	\sum_{m = 1}^p \sum_{j = 1}^S a_{mj} \delta q_j = \sum_{j = 1}^S (\sum_{m = 1}^p a_{mj}) \delta q_j = 0
\end{equation}
and this expresses that the virtual work shall vanish. In principle, this is how we handled things before already, but there is a subtle difference now: Instead of assuming that the virtual work vanishes because we have selected displacements consistent with the constraints, we must now demand impose this as a condition while solving the equations of motion.

This might make sense intuitively now, but we are still missing something: Eq.~\eqref{eq:pfaffian_deltas_as_work} is not just the sum of the different constraints, but rather the reweighted linear combination \todo{better wording}. The reason that the factors $\lambda_m$ are needed here is that the constraint forces are not uniquely determined by constraints in Pfaffian form,
\begin{equation}
	\sum_{j = 1}^S a_{mj} \delta q_j = 0
	\quad \Rightarrow \quad
	\lambda_m \sum_{j = 1}^S a_{mj} \delta q_j = 0
\end{equation}
for an arbitrary factor $\lambda_m$. Therefore, in order to truly model constraint forces, we must introduce such a factor $\lambda_m$ for each of the constraints, which turns the total constraint force into
\begin{equation}
	\sum_{m = 1}^p \lambda_m \sum_{j = 1}^S a_{mj} \delta q_j = \sum_{j = 1}^S (\sum_{m = 1}^p \lambda_m a_{mj}) \delta q_j = 0
	\, .
\end{equation}
This is precisely Eq.~\eqref{eq:pfaffian_deltas_as_work}. Inserting this model for constraint forces into the appropriate intermediate result obtained from the d'Alembert principle (which is Eq.~\eqref{eq:principle_virtual_work_general_v2}) yields
\begin{equation}
	\eqbox{
		\sum_j \qty[\dv{t} \pdv{T}{\dot{q}_j} - \pdv{T}{q_j} - Q_j - \sum_{m = 1}^p \lambda_m a_{mj}] \delta q_j = 0
	} \, .
\end{equation}
Just as before, this result only simplifies if the $\delta q_j$ are linearly independent\footnote{Note that independent $q_j$ are much easier to find now, since we do not have to pay attention to them also being consistent with constraints. That means we can make our lives very easy and just choose $q$ to have the components of the particle positions in each component.}, whence the result reads
\begin{equation}
	\eqbox{
		\dv{t} \pdv{T}{\dot{q}_j} - \pdv{T}{q_j} = Q_j + \sum_{m = 1}^p \lambda_m a_{mj}
	} \, .
\end{equation}
This is just Eq.~\eqref{eq:principle_virtual_work_general_simplified} with an additional term; similarly, these are Lagrange equations of first kind \eqref{eq:lagrange_first_kind}, but with $Q_j$ not written out in terms of the generalized potential Eq.~\eqref{eq:generalized_potential}. Appropriate values for the $\lambda_m$ is determined automatically in the process of obtaining a solution to the equation(s) of motion, e.g., from the initial conditions.



\begin{ex}[Friction]
	contains velocity, thus non-holonomic
	
	Rayleigh dissipation function

	-> is example of non-holonomic constraint
\end{ex}



		\subsection{Hamilton's Principle}
based on minimizing action -> at least making stationary (thus also name principle of stationary action); abstract idea, but was found to yield correct results for Newton (and many more!)

second variational approach; seems to be more general than virtual work



second way to derive \Def{Euler-Lagrange equations}, under the assumptions of exclusively holonomic constraints (if some are present at all) and conservative forces


-> however, we have already seen how more general situations can be recast into something compatible with ELE; i.e.~we will not reiterate derivation with other constraints again, rather show how varying in the way we done is fine, upon certain adjustments on the result


-> as a note: we could perhaps derive results that take role of ELE in presence of non-holonomic, too (because we were able to obtain them from principle of virtual work, which is special case of least action); but we do not do here




		\subsection{Gauge Transformations}
form basis for Noether

\todo{merge with next subsection?}



		\subsection{Symmetries}
conserved quantities play important role in physics, we had already seen this

-> important role in Lagrangian mechanics as well, we can simplify problems a lot via clever choice of coordinates; -> introduce cyclic as ones on which Lagrangian is not explicitly dependent

Noether



	\section{Hamilton-Formalism}
% basically description in terms of energy instead of momentum, right? since Hamiltonian = energy (?)


		% \subsection{The Mathematical Viewpoint: Transition from Lagrange to Hamilton}
		% \subsection{The Mathematical Perspective: Moving on from Lagrange}
		\subsection{Gaining Momentum(a): Moving on from Lagrange}
% \todo{make section? As nice transition between Lagrange and Hamilton, that still provides something new in the mathematical formulation} -> not if we cut short before Legendre, then subsection is perfect

Here we introduce a very formal way of looking at the Lagrange formalism. What we have done is describe physical system in terms of time $t$, some generalized positions/coordinates $q$, and their derivatives $\dot{q} = \dv{q}{t}$.\footnote{Although $q$ has components, we do not use $\vec{q}$, since it refers to a point on a manifold now. On this abstract object, points are now distinct notions from vectors, unlike in Euclidean space.}
% As it turns out, the generalized coordinate $q_i$ live on a manifold, called \Def{configuration space}.%
As it turns out, the generalized coordinate $q_i$ are indeed coordinates, namely of a manifold called \Def{configuration space}.%
\footnote{In fact, they span this space (note that this does not mean they form a basis of it; it is just that the space consists of all possible $q$). \todo{but doesn't span mean they represent a basis? -> I guess we can just argue via linear independence; same for $v_i, q_i$ as basis tangent, cotangent space}}
The \Def{configuration} of a system at each time $t$ is an element of this space, \todo{so $q(t)$ is a curve in this space}. We could also include $t$ in the space, which yields the \Def{event space}. Both of these spaces can be used to visualize the Lagrange formalism; in the latter, the evolution traces out a curve that is more like a graph, while in the former, time is an \enquote{external} parameter and we have curves only as a function of the $q_i$.


Similarly, the tangent space is spanned by the basis tangent vectors $\pdv{q_i}$ and $\dot{q} = \dv{q}{t}$ lives on it.\todo{isn't that just components of $\dv{t}$ for these Gaussian basis vectors? Since chain rule yields $\dv{t} = \sum_i \dv{q_i}{t} \dv{q_i} = \sum_i \dv{q_i}{t} \pdv{q_i}$ -> yeah, I guess we just define it in coordinates (i.e.~in a chart) here} The pair $(q, \dot{q})$ then lives on something that is referred to as tangent bundle (which is what we get by gluing together the tangent spaces at different points of the manifolds; this is like fibers forming a bundle and justifies the given name), and the Lagrangian is function on that (that has additional parameter in the time $t$).\\


Lagrangian is the perfect keyword here. The way that Lagrangian mechanics works is by solving the ELE \todo{make sure this acronym is introduced}. One practical issue with this approach is that the ELE are second order differential equations, and the total time derivative in particular can lead to very nasty and complicated expressions. Therefore, while we love the capabilities of the Lagrange formalism, it is worthwhile exploring potential alternative formulations of the problem.

After what we said about the underlying mathematical structure, namely that $(q, \dot{q})$ being part of tangent bundle, people familiar with manifolds and differential geometry will (hopefully) agree that it is straightforward to look at the cotangent bundle next. This is obtained by gluing together cotangent spaces, whose elements are maps on the tangent spaces (similarly, tangent vectors as elements of tangent spaces can be considered maps on the cotangent space, there is a duality here), and the term usually used for it in physics is \Def{phase space}. The dual or conjugate variable to $p$ that we are interested in is the \Def{generalized momentum} $\vec{p}$, defined by its components $p_i = \pdv{\mathcal{L}}{q_i}$. \todo{is this natural choice? Or more like "we choose mapping on tangent bundle because it yields good results after Legendre transform"? Which would be fine, this is what we do anyway -> hm actually comes out of Legendre naturally; so maybe not introduce here?}


You may ask why exactly we should do this? Well, the inclusion of a derivative directly into the definition of the $p_i$ should make us hopeful that this may reduce the number of differentiations to carry out. At least, it looks promising enough to follow through.\footnote{This justification is very hand-wavy. To me, this looks like a classical case of: two approaches exist (Lagrangian, Hamiltonian), and people found this cool mathematical relation between them. So this serves as our transition between them. I might be wrong, and a better justification other than \enquote{something good comes out of switching to the conjugate variables} might exist.} This is done in the next section.


-> incorporate following? note that tangent space and cotangent space are manifolds themselves; in particular, one can do things like integrals on them, something that we will see later on with Liouville measure etc; they even got a name, phase space (or state space \todo{this is the german name, certainly not english}, if time is included as well)



		\subsection{Hamiltonian and Hamilton's Equation}

Mapping $(q, \dot{q}) \mapsto (q, p)$ is conceptually very simple as it merely requires calculating the generalized momenta $p_i = \pdv{\mathcal{L}}{q_i}$. But this is not really helpful in itself -- how can we do the same physics as before, i.e.~how can we get what $\mathcal{L}$ is for $\dot{q}_i$ in terms of the $p_i$? Here it finally pays off that we had done before in linking all the physical quantities to fancy mathematical entities; as it turns out, the problem of mapping quantities from the tangent bundle to the cotangent bundle is a problem that is encountered frequently (enough) that a general solution for it exists: the \Def{Legendre transform}\footnote{Fun fact: this transform is also a prominent part of thermodynamics.}; for a function $f(x)$ of two scalar variables $x, y$, the Legendre transform with respect to $x$, is defined as
\begin{equation}
	\eqbox{
		% \Leg\qty[f](u) = \eval{\sup_x \qty{u x - f(x)}}_{x = x(u)}
		\Leg\qty[f](u) = \sup_x \qty{u x - f(x)}
	}
\end{equation}
(formally, it is only applicable in this form if $f$ is convex; we do not care about this because Lagrangians are convex in $\dot{q_i}$). If $f$ is differentiable, this turns into
\begin{equation}
	\eqbox{
		\Leg\qty[f](u) = u x(u) - f(x(u)), \; u = \dv{f}{x}, x(u) = \qty(\dv{f}{x})^{-1}(u)
	} \, .
\end{equation}
For $f$ that have more than one variable, we just keep the other variables fixed (and total derivative must be replaced by partial derivative).


Legendre-transforming the Lagrangian $\mathcal{L}(q, v)$ with respect to $v$ then yields the \Def{Hamiltonian}
\begin{equation}\label{eq:hamiltonian_general}
	\eqbox{
		H(q, p) = \Leg\qty[\mathcal{L}(q, v)](p) = \sup_v \qty{p \cdot v - \mathcal{L}(q, v)}
	}
\end{equation}
where we begin using the abbreviation $v = \dot{q}$ for \Def{generalized velocity}. \todo{I am sure this is introduced beforehand when summary is in more finalized state, adjust this}
Note that this definition holds even for non-differentiable Lagrangians, where we cannot define $p_i$ in the way that we did, but rather take them to be some arbitrary variable. But if $\mathcal{L}$ is differentiable, we can indeed recover the previous definition. This can be done by determining the supremum (maximum) via differentiation:
% 
% Please note that, if we had not defined the $p_i$ as $\pdv{\mathcal{L}}{q_i}$, we would get the same result now. For this, suppose $\mathcal{L}$ is differentiable. Then we can find the supremum (maximum) via differentiation:
\begin{equation}
	0 = \pdv{v_i} \qty(p \cdot v - \mathcal{L}) = p_i - \pdv{\mathcal{L}}{v_i}
	\quad \Leftrightarrow \quad
	p_i = \pdv{\mathcal{L}}{v_i}
	\, .
\end{equation}
Inserting this into Eq.\eqref{eq:hamiltonian_general}, the Hamiltonian becomes
\begin{equation}\label{eq:hamiltonian_differentiable}
	\eqbox{
		% H(q, p) = \Leg\qty{\mathcal{L}(q, v)}(p) = \sum_i p_i v_i(p) - \mathcal{L}(q, v)
		H(q, p) = \Leg\qty[\mathcal{L}(q, v)](p) = p \cdot v(p) - \mathcal{L}(q, v)
	} \, .
\end{equation}


Now, in general we have
\begin{equation}
	% dH(q, p, t) = \sum_i \pdv{H}{q_i} dq_i + \pdv{H}{p_i} dp_i + \pdv{H}{t} dt \, .
	dH(q, p, t) = \pdv{H}{q} \cdot dq + \pdv{H}{p} \cdot dp + \pdv{H}{t} dt \, .
\end{equation}
Inserting Eq.~\eqref{eq:hamiltonian_differentiable} here yields:\footnote{We do not use the most general form of the Hamiltonian Eq.~\eqref{eq:hamiltonian_general} because we need $\mathcal{L}$ to be differentiable to be able to calculate $dH$.}
\begin{align}
	dH(q, p, t) &= d (p \cdot v - \mathcal{L}(q, v))
	\notag\\
	&= v \cdot dp + p \cdot dv - d \mathcal{L}(q, v)
	\notag\\
	% &= \sum_i v_i dp_i + p_i dv_i - \pdv{\mathcal{L}}{q_i} dq_i - \pdv{\mathcal{L}}{v_i} dv_i - \pdv{\mathcal{L}}{t} dt
	&= v \cdot dp + p \cdot dv - \pdv{\mathcal{L}}{q} \dot dq - \pdv{\mathcal{L}}{v} \cdot dv - \pdv{\mathcal{L}}{t} dt
	\notag\\
	% &\underset{\text{ELE, Eq. \eqref{eq:ele}}}{=} \sum_i v_i dp_i + p_i dv_i - \dv{p_i}{t} dq_i - p_i dv_i - \pdv{\mathcal{L}}{t} dt
	&\underset{\text{ELE, Eq. \eqref{eq:ele}}}{=} v \cdot dp + p \cdot dv - \dv{p}{t} \cdot dq - p \cdot dv - \pdv{\mathcal{L}}{t} dt
	\notag\\
	% &= \sum_i - \dv{p_i}{t} dq_i + v_i dp_i - \pdv{\mathcal{L}}{t} dt
	&= - \dv{p}{t} \cdot dq + v \cdot dp - \pdv{\mathcal{L}}{t} dt
	\, .
	\notag\\
\end{align}
Comparing this to the general coefficients yields the \Def{Hamilton equations}
\begin{equation}\label{eq:hamilton_eq}
	\eqbox{
		% \pdv{H}{q_i} = - \dv{p_i}{t} = - \dv{\mathcal{L}}{q_i}
		\pdv{H}{q} = - \dv{p}{t} = - \dv{\mathcal{L}}{q}
	}
	\qquad
	\eqbox{
		% \pdv{H}{p_i} = v_i = \dv{q_i}{t}
		\pdv{H}{p} = v = \dv{q}{t}
	}
	\qquad
	\eqbox{
		\pdv{H}{t} = - \pdv{\mathcal{L}}{t}
	} \, .
\end{equation}
Note of course that these are really equations for each component of $q, p$ etc., so overall these are $2S + 1$ equations.

-> this is basically analogue of ELE on the cotangent bundle instead of tangent bundle; just like ELE allowed us to get the curve $q$ for a system in configuration space (thereby also curve in tangent bundle, since we can get $\dot{q}$ from $q$\todo{right?}), i.e.~its evolution in time, we now have a way to determine curve in phase space (= cotangent bundle of configuration space\todo{too much detail?})

% we have ported the theory from (the tangent bundle of the) configuration space to phase space (= cotangent bundle of configuration space)


At this point, let us take a step back and recap what happened in this section. We have derived the Hamiltonian $H$ and corresponding Hamilton equations as analogues of Lagrangian and ELE. But what did we actually gain from that? Well, one of the primary issues with the Lagrangian approach was that the ELE ended up being second-order differential equations. The Hamilton equations, on the other hand, are first order differential equations -- goal achieved. Of course, such an advancement seldomly comes without a price: we have doubled the number of equations to solve. Nevertheless, it is often worth paying this price since the overall complexity of the problem may still be reduced.

-> especially if one of the $q_i$ does not appear in $\mathcal{L}$ (and thus also not in $H$), which is sometimes called \Def{cyclic coordinate}; in that case, there is not one but actually two equations less to solve because Eq.\eqref{eq:hamilton_eq} tells us that $p_i = \text{const}$ too


% -> ok, what this means is that using Hamiltonian is just a reformulation of what we have been able to do anyway; so, what's cool about it, why should we use it? well, one practical issue with Lagrangian is that the general form of equations of motion are second-order differential equations (total time derivative is especially nasty), and (as we will see) by including derivatives directly into the generalized momenta, the Hamiltonian is able to reduce this to first-order differential equations (at the cost of doubling the equations; but this is price we are often absolutely willing to pay, as it still results in overall simplification of the problem)

-> another advantage: Hamiltonian itself corresponds to total energy under certain circumstances \todo{show how}, so unlike Lagrangian it does (can) have a physical meaning

-> also talk about how $\dv{H}{t} = 0$ corresponds to conservation of energy; note that when energy is conserved, one has scleronom constraints, which implies $\pdv{\mathcal{L}}{t} = 0$ and thus by Hamilton equations $\pdv{H}{t} = 0$ as well (less strict criterion than vanishing of total time derivative)



% purpose of Euler-Lagrange equations (ELE) is to give us a way to find $q$ as function of $t$ for a given Lagrangian; when switching to Hamiltonian, this transition would not be complete without a similar way of obtaining $(q, p) \eqqcolon \gamma$ from a given Hamiltonian (be it that we know $H$ straight up, or get it via Legendre from Lagrangian); basically, what we want is turning ELE, i.e.~conditions on derivatives of Lagrangian, into conditions on derivatives of Hamiltonian; fortunately, we can relate Hamiltonian to Lagrangian; it is thus straightforward idea to write out the differential of Hamiltonian and then compare general coefficients to coefficients in terms of the Lagrangian (for the latter, we hope to be able to apply ELE)





		\subsection{Principle Of Least Action}
relate Hamilton principle to principle of least action

\todo{maybe remove?}


\todo{make sure following is mentioned: we can see how Hamilton equation is truly analogue of ELE on phase space by alternative derivation of them; we now vary $\mathcal{L}$ expressed using $q, p, H$ on phase space in same manner that $\mathcal{L}$ was varied on configuration space before, and this yields Hamilton equation}



	% \section{The Mathematical Deep Dive: Symplectic Structure Of Classical Mechanics}
	\section{The Mathematical Deep Dive: Symplectic Structure}

summary of all Wikipedia articles I could find on this:
% - https://en.wikipedia.org/wiki/Hamiltonian_mechanics#From_symplectic_geometry_to_Hamilton's_equations
% - https://en.wikipedia.org/wiki/Hamiltonian_vector_field
% - https://en.wikipedia.org/wiki/Tautological_one-form
% - https://en.wikipedia.org/wiki/Legendre_transformation#Analytical_mechanics
% - https://en.wikipedia.org/wiki/Generalized_coordinates
% - https://en.wikipedia.org/wiki/Canonical_coordinates

Darboux's theorem forms basis for this; states that every symplectic manifold is the phase space of some physical system (is equivalence; every phase space is also symplectic)! So this type of manifolds is really the arena of Hamiltonian mechanics!


idea: we have phase space; at every point in this, I can look at tangent space, and this point-wise mapping induces a tangent bundle

-> there is a natural mapping, given by symplectic form (also: tautological one-form), between tangent and cotangent bundle; and in a small neighborhood of certain point, Darboux guarantees this can be expressed in terms of the canonical coordinates

-> we can then write down a vector field in terms of this (the Hamiltonian vector field), $X_H = J dH$ (sometimes expressed as $J(dH)$), and solving the differential equation for this vector field on the phase space (there is a natural way to formulate this on vector fields) turns out to be nothing but solving the canonical equations (from Hamiltonian) that we have derived (if we also use knowledge from ELE)

-> ah, even better: $X_H$ is defined via $X_H(Y) = dH(Y) \coloneqq \omega_H(X_H, Y)$; this is canonical identification of one-form $\omega_H$ and vector field $X_H$, which are complementary (so $X_H$ is basically dual one to this canonical form $\omega_H$); then it takes form noted above


natural next step: Hamiltonian flow



\hrule

\todo{this is more like statistical physics, right?}


hier halt etwas mathematischere Beschreibung; die kanonischen Vertauschungsrelationen definieren nämlich mathematisch gesehen eine Basis sowie die dazu duale Basis eines Tangentialraums bzw. sogar -bündels

-> Beispiele für symplektische VR sind insbesondere die Tangentialräume von symplektischen MF

-> Satz von Darboux zeigt: jede symplektische MF ist Phasenraum eines physikalischen Systems (habe ich zumindest mal so gelesen)


gute Quelle: Nakahara DiffGeo + Topologie Abschnitt 5.4.3

	\subsection{Phasenraum}
%Die Idee der Klassischen Statistischen Mechanik ist es, ein makroskopisches Vielteilchen-System durch seine klassischen, mikroskopischen Eigenschaften zu beschreiben und die Quantenmechanik erst einmal zu vernachlässigen. Manchmal ist das hilfreich bei der Veranschaulichung, aber man muss immer beachten, dass diese Beschreibung aus verschiedensten Gründen nicht exakt ist.\\
Mathematisch ist ein Teilchen in einem Gebiet $\Omega$ beschreibbar als Phase $\gamma = (\vec{p}, \vec{q})$ bestehend aus den \Def[Koordinaten! generalisierte]{generalisierten Koordinaten} $\vec{p}, \vec{q}$ im zugehörigen \Def{Phasenraum}
\begin{equation}
\Gamma = \mathbb{R}^3 \cross \Omega = \qty{\gamma: \; \gamma = (\vec{p}, \vec{q}) \equiv \text{ Zustand}} \equiv \text{ Zustandsraum} \, ,
\end{equation}
wobei unter Umständen noch Nebenbedingungen berücksichtigt werden müssen.

? eher Konfiguration ? (p,q) ist Zustand statt Konfiguration, wenn stationäres Problem vorliegt. Dann ist ja Zeit egal und kann weggelassen werden (wie bei $\Psi$, das ja meist zeitunabhängig und dann ist eben bereits $\Psi(\vec{r})$ Zustand)

	\anm{meist ist $\vec{q} \in \Omega \subset \mathbb{R}^3$ ein Element des Ortsraumes ($\Omega$ ist natürlich $\subset \mathbb{R}^3$, da dies ja der von uns Menschen beobachtbare Raum ist) und $\vec{p} \in \mathbb{R}^3$ ein Element des Impulsraumes, der den Dualraum zum Ortsraum bildet (anschaulich, da man mit dem Impuls, der die Bewegungsrichtung und -geschwindigkeit enthält, quasi Orte aufeinander abbilden kann, sich also von einem zum anderen bewegen). Der Wechsel zwischen Orts- und Impulsraum ist übrigens mithilfe der Fourier-Trafo möglich.}


Betrachtet man nun $N$ Teilchen in Zuständen $(\vec{p}_i, \vec{q}_i)$, so ist der Phasenraum des Gesamtsystems gerade das kartesische Produkt der einzelnen Phasenräume, also
\begin{equation}
\begin{split}
\Gamma &:= \Gamma_{Ges} = \Gamma_1 \cross \dots \cross \Gamma_N = \qty(\mathbb{R}^3 \cross \Omega) \cross \dots \cross \qty(\mathbb{R}^3 \cross \Omega) = \qty(\mathbb{R}^3 \cross \Omega)^N
\\
&= \qty{\gamma: \; \gamma = \qty((\vec{p_1}, \vec{q_1}), \dots, (\vec{p_n}, \vec{q_n}))} = \qty{\gamma: \, \gamma = \qty(\vec{p_1}, \dots, \vec{p_n}, \vec{q_1}, \dots \vec{q_n})} \, .
\end{split}
\end{equation}
Durch Angabe von $\gamma \in \Gamma$ ist das $N$-Teilchen-System also vollständig beschreibbar.

	\anm{man sieht aber, dass $\dim\qty(\Gamma) = 6N$, was in realen Anwendungen sehr groß werden kann (Avogadro-Zahl ist ja $\approx 6 \cdot 10^{23}$ !), daher ist das nicht immer die beste Möglichkeit (siehe StaPhy).}\\

Oft ändert man nun noch die Indizes, da nicht immer alle drei Teilchenkoordinaten zusammen benötigt werden und schreibt sie in einen Gesamtorts-/ impulsvektor
\begin{align}
p &= (p_{1,1}, p_{1,2}, p_{1,3}, \dots, p_{N,1}, p_{N,2}, p_{N,3}) = (p_1, \dots, p_{3N})
\\
q &= (q_{1,1}, q_{1,2}, q_{1,3}, \dots, q_{N,1}, q_{N,2}, q_{N,3}) = (q_1, \dots, q_{3N})
\\
\Rightarrow \quad \gamma &= (p, q) \in \qty(\mathbb{R}^{3N} \cross \Omega^{N}) = \Gamma \, .
\end{align}

! Beispiel Plot reinmachen von Phasenraum Harmonischer Ossi, da sieht man mögliche (p,q)-Paare zu fester Energie, Masse = Nebenbedingung !



	\subsection{Funktionen auf $\Gamma$}
Ein Beispiel für eine Funktion auf dem Phasenraum ist die Hamilton-Funktion $H$ (wie Hamilton-Operator), die gleichzeitig die Energie beschreibt und definiert ist als
\begin{align}
H: \Gamma \rightarrow \mathbb{R}, \; \gamma \mapsto H(\gamma) = \sum\limits_{i = 1}^N \qty(\frac{\vec{p}^{\;2}_i}{2m} + V_1(\vec{q}_i)) + \sum\limits_{i,j = 1; i \neq j}^N V_2(\vec{q}_i - \vec{q}_j) \, .
%\\
%&= \sum\limits_{j = 1}^{3N} \qty(\frac{p_j^2}{2m} + V_1(q_j)) + \sum\limits_{i,j = 1; i \neq j}^{3N} V_2(\vec{q}_i - \vec{q}_j) .
\end{align}

	\anm{damit das Phasenraumvolumen eines Teilchens endlich ist, braucht man ein Potential, das im Unendlichen divergiert, da es sonst frei beweglich ist und somit ein unendliches Volumen beim Ortsteil eingenommen wird.}



Wie in Vektorräumen üblich, existiert auch in $\Gamma$ noch mehr Struktur und zwar eine Art Skalarprodukt, es hilft hier der Satz von Darboux: er besagt, dass jeder Phasenraum in der Hamilton'schen Mechanik eine \Def[symplektisch! -e Mannigfaltigkeit]{symplektische Mannigfaltigkeit} bildet (Begriffe sind äquivalent). Das ist ein Paar $(M, \omega)$ bestehend aus einer glatten Mannigfaltigkeit $M$ mit einer \Def[symplektisch! -e Differentialform]{symplektischen Differentialform} $\omega = \sum\limits_{i,j} \omega_{ij} \, dq_i \wedge dp_j$ (glatt und geschlossen, also $d\omega = 0$), die analoge Rollen zu Vektorräumen mit alternierenden Bilinearformen/ Skalarprodukten einnehmen.

! siehe OneNote $\rightarrow$ StaPhy Zusammenfassung für sehr hilfreiche Aufgabe ! dazu in Übung 10 MfP angucken, die man $\pdv{x}$ in einer Differentialform auswertet und paar andere coole Sachen ! w anscheinend mit Koeffizienten 1 !

Auf dieser Grundlage kann man die sogenannte \Def{Poisson-Klammer} definieren als
\begin{equation}
\qty{f,g}_{p,q} = \sum\limits_{i = 1}^{3N} \pdv{f}{q_i} \pdv{g}{p_i} - \pdv{f}{p_i} \pdv{g}{q_i} = \sum\limits_{i,j} \omega^{ij} \, \partial_i f \, \partial_j g \, ,
\end{equation}
das gilt nur in gewählten Koordinaten !!! ? hatte vorher 6N, aber das kann nicht sein oder ? -> dort wahrscheinlich mit symplektischer Matrix gearbeitet

wobei die Indizes $p,q$ oft weggelassen werden, da sie die Basis kennzeichnen und die Auswertung basisunabhängig ist (folgt aus den Eigenschaften von Differentialformen).

Es lassen sich direkt einige grundlegende Relationen nachrechnen, die \Def[Poisson-Klammer! fundamentale]{fundamentalen Poisson-Klammern}:
\begin{equation}
\{q_k, q_l\} = 0 \hspace{1cm} \{p_k, p_l\} = 0 \hspace{1cm} \{q_k, p_l\} = \delta_{kl} \, .
\end{equation}

Dabei muss man lediglich die folgenden Zusammenhänge ausnutzen:
\begin{equation}
\pdv{q_k}{q_l} = \delta_{kl} = \pdv{p_k}{p_l} \hspace{2cm} \pdv{q_k}{p_l} = 0 = \pdv{p_k}{q_l} .
\end{equation}

Man kann nun zeigen, dass für eine beliebige Phasenraumfunktion $F(p,q)$ gilt:
\begin{equation}
\dv{F}{t} = \qty{F,H} + \pdv{F}{t} .
\end{equation}

Um nun die Dynamik dieses Systems (Annahme: $N$ Teilchen gleicher Masse $m$) zu beschreiben, kann man einfach die generalisierten Orts- und Impulsfunktionen $p_i, q_i$ (ordnen ja letztendlich jedem Zustand $\gamma \in \Gamma$ gewisse Größen zu, sind gerade Phasenraumfunktionen; sind nicht explizit zeitabhängig) in die Poisson-Klammer einsetzen. Das Ergebnis sind die \Def[kanonisch! -e Bewegungsgleichungen]{Hamilton'schen/ kanonischen Bewegungsgleichungen}:
\begin{equation}\label{eq:kanGl}
\dot{q}_i = \qty{q_i, H} = \pdv{H}{p_i} \qquad \dot{p}_i = \qty{p_i, H} = -\pdv{H}{q_i}, \qquad i = 1, \dots, 3N \, .
\end{equation}



	\subsection{Zeitentwicklung}
Die allgemeine Lösung der kanonischen Gleichungen \eqref{eq:kanGl} zum beliebigen Anfangswert $\gamma$ beschreibt ja die Zeitentwicklung eines Systems, ordnet also jedem Zeitpunkt $t$ einen Punkt $\gamma(t) = \tilde{\gamma} = (p,q) \in \Gamma$ zu und bildet somit eine Kurve im Phasenraum (was einer Abfolge von Systemzuständen zu verschiedenen Zeiten entspricht).\\
Diese allgemeine Lösung lässt sich zu beliebigen Startwerten bestimmen (zumindest theoretisch ist das möglich, hier aber gar nicht explizit nötig) und ist deshalb allgemein mithilfe einer Abbildungs-Schar darstellbar, dem \Def[Hamilton-Fluss]{Hamilton'schen Fluss}
\begin{equation}
\mathcal{F}_t : \Gamma \rightarrow \Gamma, \; \gamma \mapsto \mathcal{F}_t \gamma \equiv \gamma(t) \, .
\end{equation}
Es folgen quasi per Definition die Eigenschaften $\mathcal{F}_0 \gamma = \gamma$, $\mathcal{F}_s \circ \mathcal{F}_t = \mathcal{F}_{s+t}, \, s,t \in \mathbb{R}$.

Benutzung Fluss ergibt hier voll Sinn, weil man so zu jedem Anfangszustand die komplette Zeitentwicklung beschreiben kann und das in einer Abbildung (fasse also den Parameter der Schar als Parameter einer Abbildung auf)
\begin{equation}
\mathcal{F}: (\mathbb{R}, \Gamma) \rightarrow \Gamma, \; (t, \gamma) \mapsto \gamma(t)
\end{equation}

	\anm{wir nehmen an, dass am Rand des Gebietes $\Omega$ die Lösung weiter gültig bleibt, das Teilchen aber $"$reflektiert$"$ bzw. $"$gespiegelt$"$ wird: $(\vec{p}_i, \vec{q}_i) \mapsto (-\vec{p}_i, \vec{q}_i)$.}\\

Vorgriff zur Statistischen Mechanik: hier beschreibt man den Zustand bzw. die Präparation von Systemen als Dichtefunktion $\rho$ (kommt z.B. aus mikrokanonischer/ kanonischer Gesamtheit), so ist dort die Zeitentwicklung des Systems gegeben durch:
\begin{equation}
\dot{\rho}_t = \qty{\rho, H} \, .
\end{equation}
Dies ist die \Def{Liouville-Gleichung}, die dem Schrödinger-Bild $\dot{\rho}_t = i [\rho, H]$ in der QM entspricht. Der Zusammenhang zum Hamilton'schen Fluss $\mathcal{F}_t$ ist $\rho_t(\gamma) = \rho\qty(\mathcal{F}_{-t} \gamma)$.\\

Will man nun ein Volumen oder eine Fläche messen, so ist dazu immer ein Maß nötig. Das auf $\Gamma$ verwendete Liouville-Maß ist dabei wie das Lebesgue-Maß definiert:
\begin{equation}
d\gamma = d^{\,3N}p \, d^{\,3N}q = dp_1 \, dq_1 \dots dp_{3N} \, dq_{3N} \equiv d^{\,3N}p \wedge d^{\,3N}q \, .
\end{equation}

Mit diesem Hilfsmittel kann man nun die beiden wesentlichen Erhaltungsgrößen im Phasenraum mit den zugehörigen Konsequenzen untersuchen, Volumen und Energie.

Die Erhaltung des Volumens (damit ist nicht die Erhaltung von $d\gamma$ gemeint, sondern des Integrals davon über eine Menge $M$ !) bedeutet einfach, dass für eine beliebige integrierbare Funktion $f$ zu jedem Zeitpunkt $t \in \mathbb{R}$ gilt:
\begin{equation}\label{eq:zeitentw}
\int_M f\qty(\mathcal{F}_t \gamma) \, d\gamma = \int_{\mathcal{F}_t^{-1} M} f\qty(\gamma) \, d\gamma = \int_M f(\gamma) \, d\gamma \, .
\end{equation}

Idee: Anwendung der Transformationsformel auf die linke Seite, das ergibt dann $f\qty(\mathcal{F}_t^{-1}(\mathcal{F}_t \gamma)) = f(\gamma)$, aber auch auf Gebiet nötig, es kommt dann $\mathcal{F}_t^{-1}M$ raus

%-> müsste links nicht auch $d\mathcal{F}_t \gamma$ stehen ??? evtl nicht, da wir ja über gleiche kurve integrieren (?)

Daraus erhält man dann mit $f = \chi_M: \Gamma \rightarrow [0,1]$ als charakteristische Funktion einer beliebigen Menge $M \subset \Gamma$ für die Volumina
%\begin{equation}
%V_{\mathcal{F}_t^{-1}M} = \int f\qty(\mathcal{F}_t \gamma) \, d\gamma %= \int f(\gamma) \, d\gamma = V_M
%\end{equation}
\begin{equation}
\int_{\mathcal{F}_t^{-1} M} d\gamma = \int_M d\gamma  \equiv \int_M \omega^{3N} \Leftrightarrow V_M = V_{\mathcal{F}_t^{-1}M} \, .
\end{equation}
Anmerkung: $\omega^{3N}$ ist gerade das $\omega$ von oben mit mehr Dimensionen (evtl. nur $\omega^N$)

(sicher -1 etc. ??? $\rightarrow$ ja, jetzt eigentlich schon; das kann man zudem safe umschreiben zu $\mathcal{F}_{-t}$ nach den Eigenschaften von Flüssen)

$\Rightarrow$ evtl. ist Bezeichnung nur missverständlich; er schreibt $\mathcal{F}_t^{-1}M = \{\gamma: \mathcal{F}_t \gamma \in M\}$, vlt. ist also gemeint, dass man sich das Volumen der zeitentwickelten $\gamma$ anschaut und wenn man das dann quasi zurückentwickelt, erhält man das gleiche Volumen wie von $M$ ? Das heißt nicht, dass gleich viele Zustände oder so (heißt es das doch evtl. ? Haben hier noch gar keine Dichte; eigentlich Aussage ist doch, dass Zustände aus $M$ auch bei Zeitentwicklung in $M$ bleiben oder ?), sondern eben nur, dass von allen Zuständen multipliziert mit der Dichte das gleiche Volumen eingenommen wird.
-> hier geht es tatsächlich einfach nur mit Transformationsformel

Wie so oft in der Physik wird (hier auch auf Grundlage des 1. Hauptsatzes -> we are at interface of mechanics and thermodynamics here!) zudem die Energieerhaltung angenommen, es soll während der Zeitentwicklung nichts davon verloren gehen. Das bedeutet einfach
\begin{equation}
H(\mathcal{F}_t \gamma) = H(\gamma), \, \forall t \, .
\end{equation}
Betrachtet man nun alle Punkte mit gleicher Energie $E$, so bilden diese eine Energiefläche $\qty{\gamma | \, H(\gamma) = E}$, die als Fläche im $6N$-dimensionalen Phasenraum genau $(6N-1)$-dimensional ist. Das heißt aber, dass sie ein Liouville-Maß von 0 haben !

Um trotzdem eine Aussage über Energieflächen treffen zu können, fügt man ihnen in der fehlenden Dimension die Ausdehnung $\epsilon$ hinzu und konstruiert so eine Energieschale $\qty{\gamma: \; E-\epsilon \leq H(\gamma) \leq E}$, die nun Liouville-messbar ist mit Maß $\neq 0$.\\
Um diese kleine Schummelei auszugleichen, teilen wir bei der Definition des Flächenintegrals über eine Energiefläche (oder einer Teilmenge davon) wieder durch $\epsilon$ und erhalten so als Integral einer beliebigen Funktion $f: \Gamma \rightarrow \mathbb{R}$ (z.B. eine Observable) 
\begin{align}\label{eq:energy}
\expval{f}_{\qty[E = H(\gamma), \, E + \epsilon]} &= \int \chi_{\qty[E = H(\gamma), E - \epsilon]} f(\gamma) \, d\gamma
\notag\\
&= \int_{\qty{\gamma | \, H(\gamma) = E}} f(\gamma) \, d\gamma = \int \delta(H(\gamma) - E) \, f(\gamma) \, d\gamma
\notag\\
&:= \lim_{\epsilon \rightarrow 0} \frac{1}{\epsilon} \int_{E-\epsilon \leq H(\gamma) \leq E} f(\gamma) \, d\gamma = \dv{E} \int_{H(\gamma) \leq E} f(\gamma) \, d\gamma \, .
\end{align}

-> müsste es nicht nur über $H(\gamma) = E$ sein, da $\epsilon = 0$, also $E - \epsilon = E$; zweite Schreibweise überhaupt nötig ???


Nach \eqref{eq:zeitentw} ist auch dieses Integral zeitunabhängig, jedoch hängen die Schalenbreite und somit der Wert des Integrals vom Inversen des Gradienten der Energie $dE$ ab.

Anmerkung: wir können die $p_i, q_i$ auf einer Energiefläche nicht beliebig groß machen, da sonst zu viel Energie dazu benötigt wird (haben aber nur konstant viel zur Verfügung)\\

Die hier Beschreibung eines Systems über eine Phase $\gamma \in \Gamma$ ist meistens jedoch überhaupt nicht praktisch, da $\Gamma$ ja $6N$-dimensional ist und $N$ oft Werte im Bereich von $10^{23}$ hat - man könnte die nötigen Datenmengen nicht speichern, geschweige denn damit rechnen. Zudem wäre es aufgrund der Quantenmechanik gar nicht möglich, ein System genau zu vermessen oder in einer Phase $\gamma$ zu präparieren.

Wie bereits ganz am Anfang angedeutet, ist es sinnvoll, auf eine nicht exakte, statistische Beschreibung zurückzugreifen, da eine genaue nicht funktioniert. Die klassische Vielteilchen-Mechanik ist also eine Statistische Mechanik.



		\subsection{Random Ergänzungen}

kanonische Trafos sind Basiswechsel (bzw. eigentlich sogar Kartenwechsel oder ?) -> jo, Karten- und Basiswechsel sind ja quasi das Gleiche; deshalb auch ruhig Interpretation als symplektische MF bringen in Kapitel nach Hamilton, da sieht man dann mathematisch genau die Physik von vorher wieder

Liouville-Gleichung folgt, weil $\rho$ Erhaltungsgröße quasi (haben $\dv{\rho}{t} = 0$ und dann Umstellen)

Nolting Band 6, Abschnitt 1.2.1 - 1.2.3 ist super zu Phasenraum !


haben auch Poisson-Klammern bei Drehimpuls (werden auf jeden Fall auf Seite 5, Band 5.2 erwähnt, sehen aber genau so aus wie die Kommutatorrelationen) !



Formulierung mit Mannigfaltigkeiten: $(q,\dot{q}) \equiv$ Punkt, Tangentialvektor ergibt Sinn als Basis des Tangentialbündels (das den Konfigurationsraum beschreibt) -> ist ja bis auf Faktor $m$ gleich mit $(q, p)$ !! Und dann ist auch $(q,p)$ als Basis des Kotangentialbündels richtig/ sinnvoll (weil wegen Trivialisierung right; Eselsbrücke: Impuls erzeugt Translationen/ Bewegung, also die Abbildung eines Punktes auf andere Punkte und ist daher was Duales)



die ganz allgemeine Form von Lagrange- und Hamilton-Formalismus ist das Wirkungsprinzip -> da dann auch guter Verweis möglich, dass GR den gleichen Lagrangian hat und nur andere Metrik, da die dort durch Gravitation und Massen beeinflußt wird (daher dann auch bisschen andere Physik)

Legendre-Trafo wechselt zwischen Tangential- und Kotangentialbündel oder?


\end{document}